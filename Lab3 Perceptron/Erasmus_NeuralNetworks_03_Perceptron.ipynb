{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erasmus Neural Networks\n",
    "http://michalbereta.pl/nn\n",
    "## Perceptron learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Exacute the examples.\n",
    "\n",
    "Then, do the tasks and send back the notebook.\n",
    "\n",
    "Change the name of this notebook according to the schema: {YourSurname}\\_{YourFirstName}\\_{OriginalFileName}.\n",
    "\n",
    "Be sure to fill all places with \"YOUR ANSWER HERE\".\n",
    "\n",
    "When ready, send the notebook, with all the necessary files zipped, to the teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple perceptron example\n",
    "\n",
    "Start with initial weights, check the answer for some input values. If there is a misclassification, update the weights.\n",
    "\n",
    "Observe that, even after one update, the perceptron is closer to the correct answer.\n",
    "\n",
    "Experiment with different starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "\n",
    "#initial weights\n",
    "w = np.array([0.3, -0.4])\n",
    "w0 = 0.1 #bias weight\n",
    "\n",
    "print('initial weights, w=',w,' w0=',w0)\n",
    "\n",
    "#input vector\n",
    "x = np.array([-0.5, 0.9 ])\n",
    "#class label, 1 or -1\n",
    "d = 1 \n",
    "\n",
    "print('example x=',x,' is from class ',d)\n",
    "\n",
    "#learning rate\n",
    "eta = 0.1\n",
    "\n",
    "\n",
    "y = np.dot(w,x) + w0\n",
    "print('weighted sum, y=',y)\n",
    "\n",
    "#activation function\n",
    "if y > 0:\n",
    "    u = 1\n",
    "else:\n",
    "    u = -1\n",
    "    \n",
    "print('percetron says: x is from class ',u)\n",
    "    \n",
    "if u!=d:\n",
    "    w[0] = w[0] + eta*x[0]*d\n",
    "    w[1] = w[1] + eta*x[1]*d\n",
    "    w0 = w0 + eta*1*d\n",
    "\n",
    "\n",
    "print('weights after update, w=',w,' w0=',w0)\n",
    "\n",
    "y = np.dot(w,x) + w0\n",
    "print('weighted sum, y=',y)\n",
    "\n",
    "#activation function\n",
    "if y > 0:\n",
    "    u = 1\n",
    "else:\n",
    "    u = -1    \n",
    "print('percetron says: x is from class ',u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple perceptron example 2\n",
    "\n",
    "Start with initial weights, check the answer for some input values. \n",
    "\n",
    "If there is a misclassification, update the weights until the answer is correct.\n",
    "\n",
    "Experiment with different starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "\n",
    "#initial weights\n",
    "w = np.array([0.3, -0.4])\n",
    "w0 = 0.1 #bias weight\n",
    "\n",
    "#input vector\n",
    "x = np.array([-0.5, 0.9 ])\n",
    "#class label\n",
    "d = 1 \n",
    "\n",
    "print('example x=',x,' is from class ',d)\n",
    "\n",
    "#learning rate\n",
    "eta = 0.1\n",
    "\n",
    "\n",
    "y = np.dot(w,x) + w0\n",
    "print('weighted sum, y=',y)\n",
    "\n",
    "#activation function\n",
    "if y > 0:\n",
    "    u = 1\n",
    "else:\n",
    "    u = -1\n",
    "    \n",
    "print('percetron says: x is from class ',u)\n",
    "    \n",
    "while u!=d:\n",
    "    w[0] = w[0] + eta*x[0]*d\n",
    "    w[1] = w[1] + eta*x[1]*d\n",
    "    w0 = w0 + eta*1*d\n",
    "    print('\\nweights after update, w=',w,' w0=',w0)\n",
    "    y = np.dot(w,x) + w0\n",
    "    print('weighted sum, y=',y)\n",
    "    #activation function\n",
    "    if y > 0:\n",
    "        u = 1\n",
    "    else:\n",
    "        u = -1    \n",
    "    print('percetron says: x is from class ',u)\n",
    "\n",
    "print('learning done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D data from normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#example data from two classes; 2D normal distributions\n",
    "num = 100\n",
    "x2 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "x1 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "\n",
    "plt.plot(x1[:,0],x1[:,1],'o')\n",
    "plt.plot(x2[:,0],x2[:,1],'o')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron online learning animation\n",
    "\n",
    "#### DO NOT USE THIS CODE AS A TEMPLATE FOR YOUR PROGRAMS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from time import time\n",
    "\n",
    "\n",
    "num = 100\n",
    "x0 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "x0 = np.hstack((np.repeat(1,num).reshape(num,1), x0)) #adding bias signal explicitly\n",
    "d0 = np.repeat(0, num)\n",
    "x1 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "x1 = np.hstack((np.repeat(1,num).reshape(num,1), x1)) #adding bias signal explicitly\n",
    "d1 = np.repeat(1, num)\n",
    "\n",
    "X = np.vstack((x0,x1))\n",
    "d = np.hstack((d0,d1))\n",
    "\n",
    "\n",
    "def perceptron(x, w):\n",
    "    u = np.dot(x, w)\n",
    "    y = 1 if u>0 else 0\n",
    "    return y\n",
    "\n",
    "epoch = 100\n",
    "eta = 0.01\n",
    "\n",
    "iteration = epoch*X.shape[0]\n",
    "\n",
    "weights = np.random.random(3) #perceptoron weights\n",
    "a = -weights[1]/weights[2]\n",
    "b = -weights[0]/weights[2]\n",
    "\n",
    "xx = np.linspace(-6 ,6 ,100)\n",
    "yy = a*xx+b\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "ax.scatter(x0[:,1], x0[:,2], color='r')\n",
    "ax.scatter(x1[:,1], x1[:,2], color='g')\n",
    "ax.plot(xx,yy, lw=2, c='k')\n",
    "\n",
    "def animate(i):\n",
    "    flag=False\n",
    "    e, p = divmod(i,X.shape[0])\n",
    "    global weights\n",
    "    y = perceptron(X[p,:], weights)\n",
    "    if y==1 and d[p]==0:\n",
    "        flag = True\n",
    "        weights -= eta*X[p,:]\n",
    "    if y==0 and d[p]==1:\n",
    "        flag=True\n",
    "        weights += eta*X[p,:]\n",
    "    if flag:\n",
    "        a = -weights[1]/weights[2]\n",
    "        b = -weights[0]/weights[2]\n",
    "        yy = a*xx+b\n",
    "        ax.clear()\n",
    "        ax.scatter(x0[:,1], x0[:,2], color='r')\n",
    "        ax.scatter(x1[:,1], x1[:,2], color='g')\n",
    "        ax.scatter(X[p,1], X[p,2], color='k', s=80)\n",
    "        ax.plot(xx,yy, lw=2, c='k')\n",
    "        ax.text(0.0, -5.0, 'epoch: {0}, sample: {1}'.format(e,p))\n",
    "        ax.set_xlim(-6, 6)\n",
    "        ax.set_ylim(-6, 6)\n",
    "    return ax,\n",
    "\n",
    "dt = 1./30\n",
    "t0 = time()\n",
    "animate(0)\n",
    "t1 = time()\n",
    "interval = 100 * dt - (t1 - t0)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=iteration, interval=interval)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron batch learning animation\n",
    "\n",
    "#### DO NOT USE THIS CODE AS A TEMPLATE FOR YOUR PROGRAMS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#example data from two classes, 2D normal distribution\n",
    "num = 100\n",
    "x2 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "x1 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "#initialization of weights - random, smal values, positive and negative values\n",
    "#w[0] is the bias weight\n",
    "w = 2*np.random.rand(3) - 1\n",
    "#w = np.zeros(3) #try it: in general, initialization of weigths to zero is not a good idea\n",
    "print(w)\n",
    "\n",
    "\n",
    "delta = 0.01 #accuracy of the grid for vizualization only\n",
    "x = np.arange(xmin, xmax, delta)\n",
    "y = np.arange(ymin, ymax, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X*w[1] + Y*w[2] + w[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.plot(x1[:,0],x1[:,1],'o')\n",
    "plt.plot(x2[:,0],x2[:,1],'o')\n",
    "\n",
    "#this function is one iteration of perceptron learning\n",
    "def update(i):\n",
    "    global w\n",
    "    print()\n",
    "    print('iteration=',i)\n",
    "\n",
    "    #perceptron responses to examplse from class 1, \n",
    "    #we assume they should be  > 0\n",
    "    ans1 = np.dot(x1, w[1:]) + w[0]  \n",
    "    errors1 = (ans1<=0).sum() # number of missclassifications from class 1\n",
    "    print('errors1=',errors1)\n",
    "    M1 = x1[ans1<=0] #selected examples that are missclassified from class 1\n",
    "    criterion1 = ans1[ans1<=0].sum() #perceptron criterion - part 1 from the class 1\n",
    "    print('criterion1=',criterion1)\n",
    "\n",
    "    #perceptron responses to examplse from class 2, \n",
    "    #we assume they should be  <= 0    \n",
    "    ans2 = np.dot(x2, w[1:]) + w[0]\n",
    "    errors2 = (ans2>0).sum() # number of missclassifications from class 2\n",
    "    print('errors2=',errors2)\n",
    "    M2 = x2[ans2>0] #selected examples that are missclassified from class 2\n",
    "    criterion2 = ans2[ans2>0].sum()#perceptron criterion - part 2 from the class 1\n",
    "    print('criterion2=',criterion2)\n",
    "    \n",
    "    #full perceptron criterion -we should minimize it \n",
    "    criterion = np.abs(criterion1) + np.abs(criterion2) \n",
    "    print('criterion=',criterion)\n",
    "\n",
    "    M1 = M1.sum(axis=0) #summed errors from class 1\n",
    "    M2 = M2.sum(axis=0) #summed errors from class 2\n",
    "    M = M1 - M2 #vector giving the direction of the change of the weights vector\n",
    "    \n",
    "    print('M=',M)\n",
    "    eta = 0.005 #learning rate\n",
    "    \n",
    "    #weights modification\n",
    "    if np.abs( M.sum() ) > 0: #or: if criterion > 0:\n",
    "        w[1] += eta*M[0]\n",
    "        w[2] += eta*M[1]\n",
    "        w[0] += eta*(errors1-errors2) #bias weight modification \n",
    "        #a trick : normalization of the weight vector\n",
    "        #connected with the learning rate - both influence the convergence of the training process        \n",
    "        w = w/np.linalg.norm(w) \n",
    "    else:\n",
    "        print('learning done')\n",
    "    print('w=',w)\n",
    "    \n",
    "    #vizualization\n",
    "    plt.clf()\n",
    "    plt.plot(x1[:,0],x1[:,1],'o')\n",
    "    plt.plot(x2[:,0],x2[:,1],'o')\n",
    "    Z = X*w[1] + Y*w[2] + w[0]\n",
    "    Z[Z>0] = 1\n",
    "    Z[Z<=0] = -1\n",
    "    im = plt.imshow(Z, interpolation='bilinear', cmap=cm.hot,\n",
    "                origin='lower', extent=[xmin, xmax, ymin, ymax],\n",
    "                vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    "\n",
    "    \n",
    "#start learning\n",
    "ani = animation.FuncAnimation(fig, update, interval=1000, blit=False)\n",
    "plt.show()\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line separating two points (no bias version)\n",
    "\n",
    "Does it work for any two points?\n",
    "\n",
    "Check for example:\n",
    "\n",
    "```\n",
    "x1 = np.array([-2, -2]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "x1 = np.array([4, 4]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "\n",
    "\n",
    "w = (x1 - x2)/2.0\n",
    "print(w)\n",
    "\n",
    "\n",
    "delta = 0.01 #accuracy of the grid for vizualization only\n",
    "x = np.arange(xmin, xmax, delta)\n",
    "y = np.arange(ymin, ymax, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.plot(x1[0],x1[1],'o')\n",
    "plt.plot(x2[0],x2[1],'o')\n",
    "plt.plot(0,0,'o') #origin\n",
    "    \n",
    "#vizualization\n",
    "Z = X*w[0] + Y*w[1]\n",
    "Z[Z>0] = 1\n",
    "Z[Z<=0] = -1\n",
    "im = plt.imshow(Z, interpolation='bilinear', cmap=cm.hot,\n",
    "            origin='lower', extent=[xmin, xmax, ymin, ymax],\n",
    "            vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    "\n",
    "plt.show()\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line separating two points (version with bias)\n",
    "\n",
    "Does it work for any two points?\n",
    "\n",
    "Check for example:\n",
    "\n",
    "```\n",
    "x1 = np.array([-2, -2]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "x1 = np.array([-2, -1]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "\n",
    "v = x1 - x2\n",
    "mid = (x1 + x2)/2.0\n",
    "\n",
    "w = v\n",
    "w0 = -v[0]*mid[0] - v[1]*mid[1]\n",
    "\n",
    "print(w, w0)\n",
    "\n",
    "print('for x1: ', np.dot(w,x1) + w0)\n",
    "print('for x2: ', np.dot(w,x2) + w0)\n",
    "\n",
    "delta = 0.01 #accuracy of the grid for vizualization only\n",
    "x = np.arange(xmin, xmax, delta)\n",
    "y = np.arange(ymin, ymax, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.plot(x1[0],x1[1],'o')\n",
    "plt.plot(x2[0],x2[1],'o')\n",
    "plt.plot(0,0,'o') #origin\n",
    "    \n",
    "#vizualization\n",
    "Z = X*w[0] + Y*w[1] + w0\n",
    "Z[Z>0] = 1\n",
    "Z[Z<=0] = -1\n",
    "im = plt.imshow(Z, interpolation='bilinear', cmap=cm.hot,\n",
    "            origin='lower', extent=[xmin, xmax, ymin, ymax],\n",
    "            vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    " \n",
    "\n",
    "plt.show()\n",
    "\n",
    "print ('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "What happens when the data generated and used for perceptron training is not linearly separable? Can the perceptron algorithm still be used? How is the value of training rate (eta) important in such a case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Prepare your own implementation of perceptron learning\n",
    "\n",
    "– Use the online or batch mode\n",
    "\n",
    "– Be ready for any number of attributes (inputs to perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Use the 5D data to train your perceptron based on examples from data5D_train.csv. Last column is the class label.\n",
    "\n",
    "Generate answers (as 1 or -1) for data in data5D_test.csv and save them to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
