{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erasmus Neural Networks\n",
    "http://michalbereta.pl/nn\n",
    "## Perceptron learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Exacute the examples.\n",
    "\n",
    "Then, do the tasks and send back the notebook.\n",
    "\n",
    "Change the name of this notebook according to the schema: {YourSurname}\\_{YourFirstName}\\_{OriginalFileName}.\n",
    "\n",
    "Be sure to fill all places with \"YOUR ANSWER HERE\".\n",
    "\n",
    "When ready, send the notebook, with all the necessary files zipped, to the teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple perceptron example\n",
    "\n",
    "Start with initial weights, check the answer for some input values. If there is a misclassification, update the weights.\n",
    "\n",
    "Observe that, even after one update, the perceptron is closer to the correct answer.\n",
    "\n",
    "Experiment with different starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights, w= [ 0.3 -0.4]  w0= 0.1\n",
      "example x= [-0.5  0.9]  is from class  1\n",
      "weighted sum, y= -0.41000000000000003\n",
      "percetron says: x is from class  -1\n",
      "weights after update, w= [ 0.25 -0.31]  w0= 0.2\n",
      "weighted sum, y= -0.20400000000000001\n",
      "percetron says: x is from class  -1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "\n",
    "#initial weights\n",
    "w = np.array([0.3, -0.4])\n",
    "w0 = 0.1 #bias weight\n",
    "\n",
    "print('initial weights, w=',w,' w0=',w0)\n",
    "\n",
    "#input vector\n",
    "x = np.array([-0.5, 0.9 ])\n",
    "#class label, 1 or -1\n",
    "d = 1 \n",
    "\n",
    "print('example x=',x,' is from class ',d)\n",
    "\n",
    "#learning rate\n",
    "eta = 0.1\n",
    "\n",
    "\n",
    "y = np.dot(w,x) + w0\n",
    "print('weighted sum, y=',y)\n",
    "\n",
    "#activation function\n",
    "if y > 0:\n",
    "    u = 1\n",
    "else:\n",
    "    u = -1\n",
    "    \n",
    "print('percetron says: x is from class ',u)\n",
    "    \n",
    "if u!=d:\n",
    "    w[0] = w[0] + eta*x[0]*d\n",
    "    w[1] = w[1] + eta*x[1]*d\n",
    "    w0 = w0 + eta*1*d\n",
    "\n",
    "\n",
    "print('weights after update, w=',w,' w0=',w0)\n",
    "\n",
    "y = np.dot(w,x) + w0\n",
    "print('weighted sum, y=',y)\n",
    "\n",
    "#activation function\n",
    "if y > 0:\n",
    "    u = 1\n",
    "else:\n",
    "    u = -1    \n",
    "print('percetron says: x is from class ',u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple perceptron example 2\n",
    "\n",
    "Start with initial weights, check the answer for some input values. \n",
    "\n",
    "If there is a misclassification, update the weights until the answer is correct.\n",
    "\n",
    "Experiment with different starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example x= [-0.5  0.9]  is from class  1\n",
      "weighted sum, y= -0.41000000000000003\n",
      "percetron says: x is from class  -1\n",
      "\n",
      "weights after update, w= [ 0.25 -0.31]  w0= 0.2\n",
      "weighted sum, y= -0.20400000000000001\n",
      "percetron says: x is from class  -1\n",
      "\n",
      "weights after update, w= [ 0.2  -0.22]  w0= 0.30000000000000004\n",
      "weighted sum, y= 0.0020000000000000573\n",
      "percetron says: x is from class  1\n",
      "learning done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "\n",
    "#initial weights\n",
    "w = np.array([0.3, -0.4])\n",
    "w0 = 0.1 #bias weight\n",
    "\n",
    "#input vector\n",
    "x = np.array([-0.5, 0.9 ])\n",
    "#class label\n",
    "d = 1 \n",
    "\n",
    "print('example x=',x,' is from class ',d)\n",
    "\n",
    "#learning rate\n",
    "eta = 0.1\n",
    "\n",
    "\n",
    "y = np.dot(w,x) + w0\n",
    "print('weighted sum, y=',y)\n",
    "\n",
    "#activation function\n",
    "if y > 0:\n",
    "    u = 1\n",
    "else:\n",
    "    u = -1\n",
    "    \n",
    "print('percetron says: x is from class ',u)\n",
    "    \n",
    "while u!=d:\n",
    "    w[0] = w[0] + eta*x[0]*d\n",
    "    w[1] = w[1] + eta*x[1]*d\n",
    "    w0 = w0 + eta*1*d\n",
    "    print('\\nweights after update, w=',w,' w0=',w0)\n",
    "    y = np.dot(w,x) + w0\n",
    "    print('weighted sum, y=',y)\n",
    "    #activation function\n",
    "    if y > 0:\n",
    "        u = 1\n",
    "    else:\n",
    "        u = -1    \n",
    "    print('percetron says: x is from class ',u)\n",
    "\n",
    "print('learning done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D data from normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#example data from two classes; 2D normal distributions\n",
    "num = 100\n",
    "x2 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "x1 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "\n",
    "plt.plot(x1[:,0],x1[:,1],'o')\n",
    "plt.plot(x2[:,0],x2[:,1],'o')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron online learning animation\n",
    "\n",
    "#### DO NOT USE THIS CODE AS A TEMPLATE FOR YOUR PROGRAMS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from time import time\n",
    "\n",
    "\n",
    "num = 100\n",
    "x0 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "x0 = np.hstack((np.repeat(1,num).reshape(num,1), x0)) #adding bias signal explicitly\n",
    "d0 = np.repeat(0, num)\n",
    "x1 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "x1 = np.hstack((np.repeat(1,num).reshape(num,1), x1)) #adding bias signal explicitly\n",
    "d1 = np.repeat(1, num)\n",
    "\n",
    "X = np.vstack((x0,x1))\n",
    "d = np.hstack((d0,d1))\n",
    "\n",
    "\n",
    "def perceptron(x, w):\n",
    "    u = np.dot(x, w)\n",
    "    y = 1 if u>0 else 0\n",
    "    return y\n",
    "\n",
    "epoch = 100\n",
    "eta = 0.01\n",
    "\n",
    "iteration = epoch*X.shape[0]\n",
    "\n",
    "weights = np.random.random(3) #perceptoron weights\n",
    "a = -weights[1]/weights[2]\n",
    "b = -weights[0]/weights[2]\n",
    "\n",
    "xx = np.linspace(-6 ,6 ,100)\n",
    "yy = a*xx+b\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "ax.scatter(x0[:,1], x0[:,2], color='r')\n",
    "ax.scatter(x1[:,1], x1[:,2], color='g')\n",
    "ax.plot(xx,yy, lw=2, c='k')\n",
    "\n",
    "def animate(i):\n",
    "    flag=False\n",
    "    e, p = divmod(i,X.shape[0])\n",
    "    global weights\n",
    "    y = perceptron(X[p,:], weights)\n",
    "    if y==1 and d[p]==0:\n",
    "        flag = True\n",
    "        weights -= eta*X[p,:]\n",
    "    if y==0 and d[p]==1:\n",
    "        flag=True\n",
    "        weights += eta*X[p,:]\n",
    "    if flag:\n",
    "        a = -weights[1]/weights[2]\n",
    "        b = -weights[0]/weights[2]\n",
    "        yy = a*xx+b\n",
    "        ax.clear()\n",
    "        ax.scatter(x0[:,1], x0[:,2], color='r')\n",
    "        ax.scatter(x1[:,1], x1[:,2], color='g')\n",
    "        ax.scatter(X[p,1], X[p,2], color='k', s=80)\n",
    "        ax.plot(xx,yy, lw=2, c='k')\n",
    "        ax.text(0.0, -5.0, 'epoch: {0}, sample: {1}'.format(e,p))\n",
    "        ax.set_xlim(-6, 6)\n",
    "        ax.set_ylim(-6, 6)\n",
    "    return ax,\n",
    "\n",
    "dt = 1./30\n",
    "t0 = time()\n",
    "animate(0)\n",
    "t1 = time()\n",
    "interval = 100 * dt - (t1 - t0)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=iteration, interval=interval)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron batch learning animation\n",
    "\n",
    "#### DO NOT USE THIS CODE AS A TEMPLATE FOR YOUR PROGRAMS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#example data from two classes, 2D normal distribution\n",
    "num = 100\n",
    "x2 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "x1 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "#initialization of weights - random, smal values, positive and negative values\n",
    "#w[0] is the bias weight\n",
    "w = 2*np.random.rand(3) - 1\n",
    "#w = np.zeros(3) #try it: in general, initialization of weigths to zero is not a good idea\n",
    "print(w)\n",
    "\n",
    "\n",
    "delta = 0.01 #accuracy of the grid for vizualization only\n",
    "x = np.arange(xmin, xmax, delta)\n",
    "y = np.arange(ymin, ymax, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X*w[1] + Y*w[2] + w[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.plot(x1[:,0],x1[:,1],'o')\n",
    "plt.plot(x2[:,0],x2[:,1],'o')\n",
    "\n",
    "#this function is one iteration of perceptron learning\n",
    "def update(i):\n",
    "    global w\n",
    "    print()\n",
    "    print('iteration=',i)\n",
    "\n",
    "    #perceptron responses to examplse from class 1, \n",
    "    #we assume they should be  > 0\n",
    "    ans1 = np.dot(x1, w[1:]) + w[0]  \n",
    "    errors1 = (ans1<=0).sum() # number of missclassifications from class 1\n",
    "    print('errors1=',errors1)\n",
    "    M1 = x1[ans1<=0] #selected examples that are missclassified from class 1\n",
    "    criterion1 = ans1[ans1<=0].sum() #perceptron criterion - part 1 from the class 1\n",
    "    print('criterion1=',criterion1)\n",
    "\n",
    "    #perceptron responses to examplse from class 2, \n",
    "    #we assume they should be  <= 0    \n",
    "    ans2 = np.dot(x2, w[1:]) + w[0]\n",
    "    errors2 = (ans2>0).sum() # number of missclassifications from class 2\n",
    "    print('errors2=',errors2)\n",
    "    M2 = x2[ans2>0] #selected examples that are missclassified from class 2\n",
    "    criterion2 = ans2[ans2>0].sum()#perceptron criterion - part 2 from the class 1\n",
    "    print('criterion2=',criterion2)\n",
    "    \n",
    "    #full perceptron criterion -we should minimize it \n",
    "    criterion = np.abs(criterion1) + np.abs(criterion2) \n",
    "    print('criterion=',criterion)\n",
    "\n",
    "    M1 = M1.sum(axis=0) #summed errors from class 1\n",
    "    M2 = M2.sum(axis=0) #summed errors from class 2\n",
    "    M = M1 - M2 #vector giving the direction of the change of the weights vector\n",
    "    \n",
    "    print('M=',M)\n",
    "    eta = 0.005 #learning rate\n",
    "    \n",
    "    #weights modification\n",
    "    if np.abs( M.sum() ) > 0: #or: if criterion > 0:\n",
    "        w[1] += eta*M[0]\n",
    "        w[2] += eta*M[1]\n",
    "        w[0] += eta*(errors1-errors2) #bias weight modification \n",
    "        #a trick : normalization of the weight vector\n",
    "        #connected with the learning rate - both influence the convergence of the training process        \n",
    "        w = w/np.linalg.norm(w) \n",
    "    else:\n",
    "        print('learning done')\n",
    "    print('w=',w)\n",
    "    \n",
    "    #vizualization\n",
    "    plt.clf()\n",
    "    plt.plot(x1[:,0],x1[:,1],'o')\n",
    "    plt.plot(x2[:,0],x2[:,1],'o')\n",
    "    Z = X*w[1] + Y*w[2] + w[0]\n",
    "    Z[Z>0] = 1\n",
    "    Z[Z<=0] = -1\n",
    "    im = plt.imshow(Z, interpolation='bilinear', cmap=cm.hot,\n",
    "                origin='lower', extent=[xmin, xmax, ymin, ymax],\n",
    "                vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    "\n",
    "    \n",
    "#start learning\n",
    "ani = animation.FuncAnimation(fig, update, interval=1000, blit=False)\n",
    "plt.show()\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line separating two points (no bias version)\n",
    "\n",
    "Does it work for any two points?\n",
    "\n",
    "Check for example:\n",
    "\n",
    "```\n",
    "x1 = np.array([-2, -2]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "x1 = np.array([4, 4]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "\n",
    "\n",
    "w = (x1 - x2)/2.0\n",
    "print(w)\n",
    "\n",
    "\n",
    "delta = 0.01 #accuracy of the grid for vizualization only\n",
    "x = np.arange(xmin, xmax, delta)\n",
    "y = np.arange(ymin, ymax, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.plot(x1[0],x1[1],'o')\n",
    "plt.plot(x2[0],x2[1],'o')\n",
    "plt.plot(0,0,'o') #origin\n",
    "    \n",
    "#vizualization\n",
    "Z = X*w[0] + Y*w[1]\n",
    "Z[Z>0] = 1\n",
    "Z[Z<=0] = -1\n",
    "im = plt.imshow(Z, interpolation='bilinear', cmap=cm.hot,\n",
    "            origin='lower', extent=[xmin, xmax, ymin, ymax],\n",
    "            vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    "\n",
    "plt.show()\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line separating two points (version with bias)\n",
    "\n",
    "Does it work for any two points?\n",
    "\n",
    "Check for example:\n",
    "\n",
    "```\n",
    "x1 = np.array([-2, -2]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] 13.5\n",
      "for x1:  6.5\n",
      "for x2:  -6.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "ymin = -6\n",
    "ymax = 6\n",
    "\n",
    "x1 = np.array([-2, -1]) #from class 1\n",
    "x2 = np.array([-4, -4]) # from class -1\n",
    "\n",
    "v = x1 - x2\n",
    "mid = (x1 + x2)/2.0\n",
    "\n",
    "w = v\n",
    "w0 = -v[0]*mid[0] - v[1]*mid[1]\n",
    "\n",
    "print(w, w0)\n",
    "\n",
    "print('for x1: ', np.dot(w,x1) + w0)\n",
    "print('for x2: ', np.dot(w,x2) + w0)\n",
    "\n",
    "delta = 0.01 #accuracy of the grid for vizualization only\n",
    "x = np.arange(xmin, xmax, delta)\n",
    "y = np.arange(ymin, ymax, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.plot(x1[0],x1[1],'o')\n",
    "plt.plot(x2[0],x2[1],'o')\n",
    "plt.plot(0,0,'o') #origin\n",
    "    \n",
    "#vizualization\n",
    "Z = X*w[0] + Y*w[1] + w0\n",
    "Z[Z>0] = 1\n",
    "Z[Z<=0] = -1\n",
    "im = plt.imshow(Z, interpolation='bilinear', cmap=cm.hot,\n",
    "            origin='lower', extent=[xmin, xmax, ymin, ymax],\n",
    "            vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    " \n",
    "\n",
    "plt.show()\n",
    "\n",
    "print ('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "What happens when the data generated and used for perceptron training is not linearly separable? Can the perceptron algorithm still be used? How is the value of training rate (eta) important in such a case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is not linearly separable, the perceptron might not converge. A too high learning rate will induce big adjustements of weights at each iteration, which in case of non linearly separable data will oscillate between extreme values and never converge. A lower learning rate will slowly adjust the weights but may take too many epochs to converge to an optimal solution. That's why if we use the perceptron, it will be important to define a maximum number of epoch and maybe also a maximum number of errors allowed. Moreover, if we already know that the data is non linearly separable, it's better to use a non linear activation function (sigmoid, hyberbolic tangent, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Prepare your own implementation of perceptron learning\n",
    "\n",
    "– Use the online or batch mode\n",
    "\n",
    "– Be ready for any number of attributes (inputs to perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "[-0.7 -0.7 -0.7 -0.6] \n",
      "errors =  1\n",
      "Epoch 1\n",
      "\n",
      "[-0.6 -0.7 -0.5 -0.6] \n",
      "errors =  2\n",
      "Epoch 2\n",
      "\n",
      "[-0.5 -0.7 -0.3 -0.6] \n",
      "errors =  2\n",
      "Epoch 3\n",
      "\n",
      "[-0.4 -0.7 -0.1 -0.6] \n",
      "errors =  2\n",
      "Epoch 4\n",
      "\n",
      "[-0.3 -0.7  0.1 -0.6] \n",
      "errors =  2\n",
      "Epoch 5\n",
      "\n",
      "[-0.2 -0.7  0.3 -0.6] \n",
      "errors =  2\n",
      "Epoch 6\n",
      "\n",
      "[-0.1 -0.7  0.5 -0.6] \n",
      "errors =  2\n",
      "Epoch 7\n",
      "\n",
      "[-2.22044605e-16 -7.00000000e-01  7.00000000e-01 -6.00000000e-01] \n",
      "errors =  2\n",
      "Epoch 8\n",
      "\n",
      "[ 0.1 -0.7  0.9 -0.6] \n",
      "errors =  2\n",
      "Epoch 9\n",
      "\n",
      "[ 0.1 -0.7  0.9 -0.6] \n",
      "errors =  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, dim, learningrate=0.1, bias=1):\n",
    "        self.weights=np.zeros(dim)\n",
    "        self.learningrate = learningrate\n",
    "        self.bias = bias\n",
    "    \n",
    "    def activation(self, x):\n",
    "        return 1 if x > 0 else -1\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        guess=[]\n",
    "        for i, input in enumerate(inputs):\n",
    "            sum=np.dot(self.weights,input) + self.bias #il faudrait incorporer le bias au weights w0\n",
    "            # Activation function \n",
    "            guess.append(self.activation(sum))\n",
    "        return guess\n",
    "    \n",
    "    def learn(self, inputs, labels):\n",
    "        epoch=0\n",
    "        errors=1\n",
    "        while errors and epoch < 100 :\n",
    "            errors=0\n",
    "            print(\"Epoch \"+str(epoch)+\"\\n\")\n",
    "            for i, input in enumerate(inputs):\n",
    "                # Scalar product weights/inputs + bias\n",
    "                sum=np.dot(self.weights,input) + self.bias \n",
    "                # Activation function \n",
    "                u=self.activation(sum)\n",
    "                if u != labels[i]:\n",
    "                    errors+=1\n",
    "                    # Ajust weights and bias \n",
    "                    for j in range(len(self.weights)): \n",
    "                        self.weights[j] += self.learningrate*input[j]*labels[i]\n",
    "                    self.bias += self.learningrate*labels[i]\n",
    "            print(self.weights, \"\\nerrors = \", errors)\n",
    "            epoch+=1\n",
    "            \n",
    "    def __str__(self):\n",
    "        return '(' + str(self.weights)  + ')'\n",
    "    def __repr__(self):\n",
    "        return '(' + str(self.weights) + ')'\n",
    "\n",
    "p1=Perceptron(4)\n",
    "p1          \n",
    "p1.learn([[8,7,9,6], [7,7,7,6], [6,7,6,6]], [1,-1,-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Use the 5D data to train your perceptron based on examples from data5D_train.csv. Last column is the class label.\n",
    "\n",
    "Generate answers (as 1 or -1) for data in data5D_test.csv and save them to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values =  [array([-0.45219426,  0.25657125, -0.9368542 ,  0.80657558, -0.79133903]), array([-0.72172939,  0.01179515,  0.40583078, -0.90642659,  0.07723489]), array([-0.04764479, -0.98419792,  0.5544936 , -0.8359505 ,  0.05949989]), array([ 0.71859074, -0.08114127,  0.4021709 ,  0.09331177, -0.88052225]), array([ 0.64350499,  0.32052622,  0.40639275, -0.71094315,  0.44726582]), array([-0.64359573, -0.73152814,  0.52228294,  0.30746542,  0.95632172]), array([0.50235318, 0.98221024, 0.61809971, 0.79572339, 0.33163849]), array([-0.36905117, -0.77977007, -0.86780395, -0.99407331, -0.99991774]), array([-0.95085337,  0.58128767,  0.88991417,  0.4544718 , -0.81981303]), array([-0.34266327, -0.25388755,  0.29505976, -0.11738547, -0.50671621]), array([ 0.23419711,  0.90957132,  0.36975825, -0.50976055, -0.84761044]), array([-0.98283687,  0.40109125,  0.56837772,  0.22437724,  0.34702004]), array([-0.29067109,  0.51960902,  0.82073838,  0.19444032,  0.22192982]), array([-0.65682617,  0.40510063,  0.4791037 , -0.94436343, -0.41764317]), array([-0.91592373, -0.5604003 , -0.97381113, -0.69060572,  0.62409209]), array([ 0.01615871, -0.2585187 ,  0.61309205, -0.15885745,  0.51663011]), array([-0.53843986,  0.73986875,  0.95171561,  0.62260872,  0.85161755]), array([-0.02700436,  0.02927978, -0.29267523,  0.99461633, -0.5580606 ]), array([-0.41901335,  0.2120434 , -0.29841189, -0.34820745,  0.78366008]), array([0.06459197, 0.39119663, 0.6950504 , 0.28914317, 0.79082235]), array([-0.56859885,  0.00823421, -0.98145221, -0.63177236, -0.67735447]), array([-0.0963606 ,  0.41499585, -0.06546381,  0.92896309, -0.48094437]), array([-0.39671738, -0.87111582,  0.32310511,  0.34531499,  0.02353776]), array([0.86881198, 0.14626883, 0.23578839, 0.12183809, 0.0834693 ]), array([ 0.03456216, -0.90592201,  0.3149592 , -0.78719588,  0.36040269]), array([-0.97101837, -0.72115745,  0.82096863,  0.43922014, -0.96207983]), array([-0.51820564,  0.36087091, -0.74709483,  0.93261379,  0.87536164]), array([ 0.58371916, -0.13677853, -0.40620877,  0.00124499, -0.83990123]), array([ 0.73131557, -0.83749806, -0.76157667,  0.90524658, -0.71387241]), array([ 0.02587461, -0.34919729,  0.02103646, -0.1050021 , -0.90841707]), array([ 0.71615077, -0.10003634, -0.94670365, -0.67020678,  0.81644891]), array([ 0.36358253, -0.40673667, -0.78975498,  0.88241988,  0.50088865]), array([ 0.28434712,  0.8305267 ,  0.59234634, -0.77647152,  0.75259824]), array([-0.39108581, -0.50765135, -0.47390559,  0.5790035 , -0.4852585 ]), array([-0.1660747 , -0.86449457,  0.59999047, -0.53750187,  0.73730838]), array([ 0.7021253 ,  0.71616212, -0.00544516,  0.04560178, -0.04393408]), array([-0.47541482,  0.69426853, -0.95609879, -0.54151896,  0.22258251]), array([-0.32819741, -0.08988027, -0.82662508,  0.19232628, -0.99404886]), array([ 0.65528431, -0.15852048, -0.37319659, -0.21378419, -0.49719836]), array([-0.48426768, -0.32460763, -0.06667639,  0.28815768,  0.46055717]), array([ 0.01519817, -0.91191524,  0.18345894, -0.74124775,  0.84657107]), array([ 0.88778355,  0.20133251, -0.81632169, -0.2257935 , -0.28966894]), array([ 0.59529964, -0.03811695, -0.95544961, -0.96746576,  0.47776512]), array([0.64936232, 0.0784038 , 0.79620092, 0.66544027, 0.00750993]), array([-0.69894013,  0.9865525 , -0.89819858, -0.50982486,  0.43751713]), array([ 0.92467608, -0.00846716,  0.30209917, -0.43001712,  0.20823205]), array([ 0.16355247, -0.8487802 ,  0.82097931,  0.703171  ,  0.11873563]), array([ 0.52445445,  0.68990033, -0.57271403,  0.01070636,  0.66602146]), array([ 0.67134816,  0.45426602, -0.5368494 , -0.74555721, -0.31502645]), array([-0.74039774,  0.24922524,  0.89901269,  0.25660174,  0.3283619 ]), array([ 0.01030717, -0.23047605, -0.90788329,  0.37354578, -0.11775129]), array([-0.06549122,  0.61702476,  0.6479958 , -0.04892931,  0.18771887]), array([ 0.21724794, -0.27408539,  0.52062935, -0.21221262,  0.60366815]), array([-0.19590504, -0.61787292, -0.56538771, -0.47937532,  0.87407183]), array([-0.12896659,  0.10406815, -0.83145131,  0.13521059,  0.75936124]), array([-0.68984064,  0.70824913, -0.02477248, -0.67186831,  0.49260487]), array([-0.59038483,  0.53274895,  0.90868937,  0.07479484,  0.59926884]), array([0.3870848 , 0.58021108, 0.43128302, 0.68454951, 0.66567876]), array([ 0.36761342, -0.44760617, -0.1999028 ,  0.36485978, -0.56834878]), array([-0.80519485,  0.07026536,  0.36686577,  0.43641792, -0.20780652]), array([ 0.55719479, -0.42105227, -0.15186956,  0.60846225, -0.64795952]), array([ 0.56652608, -0.44848952,  0.34786499, -0.8699838 , -0.30344104]), array([-0.83132222, -0.33878332,  0.93193572,  0.75421183,  0.02975372]), array([ 0.9022389 , -0.62838728, -0.45721208, -0.6724483 , -0.8859263 ]), array([ 0.62850541, -0.79828278,  0.62766708,  0.31648103, -0.61681181]), array([-0.60749671, -0.78528236, -0.6949223 ,  0.37807604, -0.3851459 ]), array([ 0.95639705, -0.9530288 , -0.88293533, -0.92848555,  0.77326055]), array([ 0.49520982, -0.52023237, -0.63153028,  0.45582347,  0.13994547]), array([ 0.38624174,  0.06281091, -0.98452503,  0.59799835,  0.93108376]), array([-0.39947923,  0.56807385, -0.35157182,  0.27628176,  0.63325554]), array([-0.55424018,  0.50716589, -0.62120251,  0.52881483,  0.27751635]), array([-0.32323879, -0.24822042, -0.22611564, -0.53397807, -0.65936496]), array([ 0.65662949,  0.53531351, -0.11480305, -0.10041379, -0.56834979]), array([-0.48513779, -0.68827822,  0.63194303,  0.00502436, -0.09494628]), array([-0.29148821,  0.72453361, -0.92511672,  0.51431759, -0.2332167 ]), array([ 0.0866844 ,  0.01237725, -0.62085251, -0.91160128, -0.26789542]), array([-0.30706364,  0.72733416,  0.93060188, -0.74292064, -0.46214834]), array([ 0.58003874, -0.64425464, -0.37409791,  0.23006922, -0.37712593]), array([ 0.75555969, -0.09199724, -0.30063917,  0.48323419,  0.88680119]), array([-0.95480015, -0.50186855,  0.80104225,  0.31809774,  0.8879282 ]), array([-0.85912028,  0.70579721,  0.60914639, -0.85703037,  0.9978463 ]), array([ 0.57813338, -0.73052232,  0.01370352, -0.73302391, -0.28616372]), array([ 0.70122622, -0.61708278,  0.48244872, -0.11894647,  0.7963488 ]), array([-0.23659747,  0.12470224, -0.85881983, -0.66754007,  0.48940178]), array([-0.98015769, -0.73738582, -0.35351596,  0.32758261, -0.02772044]), array([-0.44966989, -0.34829367, -0.22265149, -0.84326159, -0.41678388]), array([ 0.86583352, -0.71920366, -0.09179045, -0.80089443,  0.66273358]), array([-0.72060823, -0.20059442,  0.40575827, -0.72232148,  0.04670032]), array([ 0.86088865,  0.589947  ,  0.54900589, -0.10120742,  0.18156819]), array([-0.0138017 , -0.92597454,  0.10865356, -0.41335046,  0.39382136]), array([-0.14699967,  0.47268624, -0.11458988, -0.84350282,  0.10784468]), array([-0.43816703,  0.34735398,  0.89505656, -0.9681461 ,  0.57262679]), array([ 0.99266373,  0.29417709, -0.56721746,  0.43852303, -0.06823366]), array([ 0.0723208 , -0.36536974,  0.58289323,  0.58305808, -0.59374819]), array([-0.22457662, -0.28060154,  0.29175132,  0.50394195, -0.5114033 ]), array([ 0.70581518,  0.74169118, -0.81390584,  0.7437611 , -0.49105627]), array([ 0.71438104, -0.53707358, -0.52660389, -0.02298212,  0.0989558 ]), array([ 0.88708606,  0.49625574, -0.40241084, -0.74610708,  0.5152309 ]), array([-0.17017816,  0.22224339, -0.78800127,  0.04073454,  0.28465306]), array([ 0.2600054 ,  0.0591245 , -0.57594758, -0.5883345 ,  0.55216845]), array([ 0.36436894,  0.21527695,  0.17699057, -0.91225377, -0.0984043 ]), array([-0.24055879,  0.73913258, -0.46726992, -0.72317763,  0.56500308]), array([0.32002177, 0.78082889, 0.17082983, 0.07955345, 0.61204141]), array([ 0.91812044,  0.59000564, -0.33865525, -0.60713411,  0.99997223]), array([ 0.45980867, -0.02875719, -0.87641257,  0.24403231, -0.88687359]), array([ 0.61902272, -0.29411609,  0.18365181, -0.86301583, -0.71204795]), array([-0.21950571, -0.64931592, -0.01728689, -0.12739028, -0.02935874]), array([ 0.33484332, -0.30406639, -0.43103351, -0.36762121, -0.89233447]), array([-0.89036666, -0.60717253,  0.92600934, -0.34852855,  0.77694781]), array([-0.59852037,  0.70342891, -0.05113025,  0.73117423, -0.18888289]), array([-0.94745057, -0.66456865, -0.02406212,  0.62320534,  0.60388726]), array([-0.8448514 ,  0.00690445,  0.13795041,  0.02418137, -0.12060472]), array([-0.57917298, -0.76414985,  0.17690541, -0.99008145,  0.82975988]), array([ 0.01915773, -0.65957047, -0.42706957,  0.18450968, -0.99424014]), array([-0.20730128,  0.03210795, -0.16943025,  0.38550593, -0.48791432]), array([ 0.75073191, -0.77971511,  0.26667902,  0.45528687, -0.84674402]), array([-0.29759735, -0.21875674,  0.02895041, -0.38679148,  0.58354327]), array([-0.40827073,  0.61751621, -0.64309002,  0.21048177, -0.3457057 ]), array([-0.64726592, -0.35447577,  0.84414595,  0.28472602, -0.60769216]), array([ 0.55533003, -0.29518134, -0.66297143, -0.27282577,  0.07133577]), array([-0.10377767,  0.39522706,  0.73342261, -0.61612278, -0.23562466]), array([ 0.54753518, -0.59930964, -0.05690137,  0.56758738,  0.38628264]), array([-0.27803495,  0.3573    ,  0.99557672, -0.36231112, -0.86887216]), array([ 0.3403962 ,  0.60798429, -0.92214622,  0.31495369, -0.14385303]), array([ 0.088914  , -0.32786987, -0.7481417 , -0.53209965,  0.42579104]), array([-0.78451533, -0.29521585, -0.17437311, -0.45748673,  0.37196405]), array([ 0.43781574, -0.12346212,  0.23738408,  0.67055698, -0.08385731]), array([-0.05120107,  0.10461672,  0.16122982, -0.30663246,  0.24884827]), array([-0.0382583 ,  0.52400947, -0.73050104,  0.85135593,  0.93783527]), array([-0.84218448, -0.56526145, -0.13204214,  0.09749681,  0.5049932 ]), array([-0.10691469,  0.94542871, -0.01089737, -0.16748397, -0.90656935]), array([-0.71193969,  0.1837419 ,  0.69015985, -0.30520118, -0.58223896]), array([-0.63308512,  0.81240069, -0.83278606,  0.20494591, -0.61967499]), array([-0.52175072, -0.49071017, -0.57097306,  0.09075257,  0.90607902]), array([ 0.52838537, -0.25043418, -0.06089353, -0.20928263,  0.03009791]), array([-0.31098761,  0.54117743,  0.05707077, -0.79493867,  0.15433449]), array([ 0.35914445, -0.66632411,  0.05946752, -0.10019673, -0.90141307]), array([ 0.75640823, -0.23527031,  0.84442182,  0.08402332, -0.24177397]), array([-0.35994172,  0.4839043 ,  0.97213385, -0.01198755,  0.15213435]), array([ 0.97799177, -0.31542535,  0.19272411,  0.31930637, -0.89222749]), array([-0.3318386 ,  0.11676716, -0.66247644, -0.76840401, -0.16648766]), array([ 0.53751144,  0.26854671, -0.22025617,  0.44140353, -0.40549813]), array([-0.9943068 , -0.80697065,  0.30917359,  0.2256392 ,  0.17661729]), array([ 0.22720874, -0.64624097, -0.72345897, -0.39982829, -0.61728962]), array([ 0.98709181, -0.01221342, -0.43964723, -0.62576568, -0.6455218 ]), array([ 0.57231654,  0.90386789, -0.99655645, -0.01747105, -0.81105991]), array([-0.83558304,  0.86309856, -0.59157869,  0.56809776, -0.85112256]), array([ 0.73757806, -0.44448178, -0.43431473, -0.82357836,  0.40144846]), array([ 0.68527391, -0.65609172, -0.47635975,  0.74278554,  0.57626187]), array([-0.62898067, -0.07106988,  0.13212112,  0.7369175 , -0.81571706]), array([-0.95272773,  0.61751452,  0.13355837, -0.39303828, -0.42939084]), array([-0.23581184, -0.78835638, -0.06928501, -0.3908324 , -0.27929792]), array([-0.69796303,  0.36249321,  0.04550475, -0.57019083,  0.66950408]), array([-0.84962633,  0.00801798, -0.35621522,  0.7344333 ,  0.63678296]), array([ 0.61120588,  0.51907916, -0.10551278,  0.72480091, -0.30863285]), array([ 0.62389248,  0.78151669, -0.87292767, -0.66865365,  0.83560488]), array([ 0.97320981, -0.38691269,  0.61622301, -0.72571186, -0.27352308]), array([-0.76670274,  0.8507784 ,  0.86485777, -0.70898062,  0.97562737]), array([-0.58983965, -0.38473162,  0.62540866,  0.30963013,  0.42869379]), array([-0.92632689,  0.04853355, -0.29404455,  0.83947668, -0.15357534]), array([-0.23941096,  0.96739292, -0.23803878, -0.78661911,  0.56075107]), array([ 0.93643504, -0.91327403, -0.40337946, -0.94357365, -0.73812241]), array([-0.74678465,  0.29180515,  0.14646129, -0.48343099,  0.57311385]), array([ 0.51713317, -0.71366344, -0.26581289,  0.76005164,  0.23518643]), array([-0.02137922,  0.82862051,  0.15495476, -0.77213111, -0.99378104]), array([-0.70508113, -0.53659389, -0.8668264 , -0.16698238, -0.45758987]), array([ 0.92980664, -0.05266623, -0.40098597,  0.52073682,  0.59638288]), array([-0.69105421, -0.82482571, -0.96803896,  0.52500423,  0.93866184]), array([-0.23307671, -0.38028161,  0.82036526,  0.01709952,  0.8129738 ]), array([ 0.17150409,  0.71096537,  0.66233728, -0.55957338, -0.80787822]), array([-0.02673008, -0.90967759, -0.1669131 ,  0.76272046, -0.91964485]), array([ 0.3388116 ,  0.79607251, -0.53713561, -0.1112303 , -0.87375805]), array([-0.96723463, -0.93276096, -0.84050669, -0.46080047,  0.39777702]), array([ 0.34507409,  0.90074084, -0.9521958 , -0.60992531, -0.80690599]), array([-0.0053288 , -0.45490869,  0.8176299 , -0.91992181, -0.29039392]), array([0.05316826, 0.46005006, 0.28830047, 0.76080881, 0.52249097]), array([ 0.69852306, -0.61138837, -0.27561003,  0.64575749,  0.2158013 ]), array([ 0.25000988, -0.28515364,  0.33671821, -0.90805697, -0.76955554]), array([ 0.50585856,  0.52613575,  0.91730835, -0.0377726 ,  0.63009966]), array([ 0.4507216 ,  0.59787941, -0.00657044,  0.16392371,  0.83332144]), array([ 0.67937171, -0.13234188,  0.46337832, -0.15470235, -0.07858357]), array([ 0.77023913, -0.09595296,  0.33852868,  0.25491156,  0.99931079]), array([ 0.02252191, -0.13607927, -0.37404512, -0.58865118,  0.88627622]), array([-0.14694507,  0.62416035, -0.82202721,  0.34987448,  0.39024887]), array([-0.25673937,  0.9233982 ,  0.42432554, -0.28689392, -0.88961192]), array([ 0.76605911,  0.55329445, -0.69248274, -0.05493901, -0.02042373]), array([-0.29151146, -0.91131034, -0.30319032,  0.06875376,  0.96395087]), array([ 0.84387764,  0.15684209, -0.89773089, -0.68914711,  0.12664731]), array([-0.51178492,  0.338972  , -0.21033535, -0.69162659,  0.2829302 ]), array([ 0.66106873,  0.46603589, -0.08468491, -0.17254236,  0.47363167]), array([-0.09116245, -0.41121499, -0.4915794 , -0.91283978, -0.92583104]), array([-0.22983208,  0.12333492,  0.95938051, -0.70835396, -0.53211203]), array([-0.48739822,  0.90677937,  0.14676943,  0.30954172, -0.43877529]), array([ 0.44065072, -0.26990198,  0.23306576,  0.51954122, -0.62700038]), array([ 0.43855065, -0.84988273, -0.78583655, -0.41770239,  0.60306896]), array([-0.12833959,  0.38604261,  0.25944296,  0.89206062, -0.5404336 ]), array([ 0.99525591, -0.73696145, -0.09806636,  0.41847428, -0.1251921 ]), array([-0.91365801, -0.33247251, -0.38218549, -0.90140828,  0.09325131]), array([-0.94547555, -0.97713697, -0.6983752 , -0.44284592, -0.15511021]), array([ 0.57670763,  0.45786139, -0.8464634 ,  0.22368086,  0.46672466]), array([-0.50292941, -0.14524875,  0.3033326 , -0.83244122,  0.60275935]), array([ 0.14696498, -0.0130336 , -0.9544174 , -0.76883716, -0.93066983]), array([ 0.4605574 ,  0.07552076,  0.42922829, -0.26959522, -0.42386181]), array([ 0.76293742,  0.38319878,  0.47291857, -0.3109036 , -0.16649685]), array([-0.48632721,  0.91036582, -0.20479389,  0.65507132,  0.71047757]), array([-0.74384705, -0.32798667, -0.61847642,  0.99343713, -0.73504347]), array([ 0.06519577, -0.52973845,  0.93755758, -0.37463189,  0.46757495]), array([ 0.00917246, -0.62010962,  0.73766784, -0.84971273, -0.78894036]), array([-0.24947925,  0.47730755,  0.84194152,  0.29618117,  0.91867965]), array([-0.24064832,  0.49598002,  0.72146753, -0.96481914, -0.54403495]), array([-0.77083685, -0.1551626 , -0.66966378,  0.82207328, -0.94446354]), array([-0.5367379 ,  0.11300175, -0.36873792,  0.1324498 ,  0.00707599]), array([-0.54400702, -0.40951069,  0.4848258 ,  0.92323493,  0.2423113 ]), array([-0.81318637, -0.16260078, -0.55952082, -0.52644059,  0.74737973]), array([-0.77338276, -0.07704983,  0.76125083, -0.85861993,  0.93529906]), array([-0.53578718,  0.56150234, -0.57249778,  0.68564873,  0.17908872]), array([-0.62865013,  0.46485267,  0.40686166, -0.80514852, -0.36288486]), array([-0.90513703, -0.8209488 , -0.74892728,  0.25328398, -0.41693226]), array([-0.44712087,  0.73007212,  0.67169802,  0.08513365, -0.7634269 ]), array([ 0.65156539,  0.38867873, -0.33234548, -0.23097948,  0.31562576]), array([ 0.13866479, -0.33882505, -0.34578337,  0.89033446, -0.74778087]), array([ 0.67252526, -0.46937321,  0.67457769,  0.13605885,  0.15693158]), array([-0.51786884,  0.20945828, -0.87112681,  0.41302668, -0.54573892]), array([-0.02503856, -0.98066118,  0.75746585, -0.17075468,  0.93813564]), array([-0.42446933,  0.33583488,  0.72426273,  0.01356512, -0.82017673]), array([ 0.18384959, -0.39573024, -0.62863411,  0.28840835, -0.18169838]), array([-0.872071  , -0.09322456, -0.27017039,  0.20452875,  0.76685418]), array([ 0.27928546,  0.94488543, -0.08070346,  0.42813282,  0.794116  ]), array([-0.36351022, -0.79463935, -0.9298673 , -0.03677886,  0.7502027 ]), array([-0.55289468, -0.6984626 ,  0.83767957,  0.22435809, -0.31690156]), array([-0.70134426,  0.63432436, -0.29829838,  0.96911984, -0.89936129]), array([-0.37627546, -0.3944814 , -0.11540616,  0.28280295, -0.94363798]), array([ 0.54678291, -0.58993626,  0.04540232, -0.57787163,  0.14154229]), array([0.71398031, 0.62191635, 0.33822468, 0.14888964, 0.60645506]), array([ 0.63213883,  0.22582352,  0.18101506, -0.76711386,  0.6914671 ]), array([ 0.97079969, -0.20405969, -0.78051371, -0.60684028,  0.16448565]), array([ 0.10458641,  0.14285429, -0.83392911, -0.31853871, -0.19922383]), array([ 0.42636265, -0.47528701, -0.6980328 ,  0.33500022, -0.92955809]), array([-0.77572658,  0.70692667,  0.60343601, -0.01964097,  0.85794777]), array([ 0.42971812, -0.54179311, -0.90561158, -0.05072004, -0.63240582]), array([-0.30361742, -0.51723311, -0.53022783, -0.92915724, -0.79325759]), array([-0.33496805,  0.43248738, -0.07142218, -0.23469708, -0.28073591]), array([-0.41669499,  0.90548462, -0.89188538, -0.17781083,  0.15314363]), array([-0.39982007,  0.4541976 , -0.19710206, -0.19794523, -0.61268097]), array([-0.64725346, -0.70735442,  0.58779664, -0.64245122,  0.24132882]), array([-0.57209889,  0.04884913, -0.99590975,  0.89719929, -0.93527875]), array([-0.47667772, -0.3357097 , -0.18932723, -0.09052286,  0.31589842]), array([ 0.56667757,  0.41334257,  0.04015037, -0.70176821, -0.97153122]), array([ 0.07752516,  0.86650203, -0.90074221, -0.10324886, -0.16747986]), array([-0.20591004, -0.49435177, -0.58277619,  0.10684049,  0.90090078]), array([-0.31439986,  0.41405287,  0.19245826,  0.51524682, -0.64098675]), array([ 0.18432488, -0.41812487, -0.66262459,  0.38152501, -0.97652391]), array([-0.94237952,  0.20860797, -0.15710755, -0.17219773,  0.55538902]), array([-0.60142749,  0.56838217, -0.27113484, -0.26819994,  0.37724019]), array([ 0.86271901, -0.56474531, -0.50743548, -0.84109496,  0.86201631]), array([-0.51595456,  0.55452289,  0.90095007, -0.45995681,  0.96069264]), array([-0.53633881,  0.21950747, -0.7277635 ,  0.93808964, -0.69005699]), array([ 0.62344482,  0.19686849,  0.44602597,  0.57352447, -0.39397801]), array([-0.58154299, -0.97101872, -0.66226489,  0.6083188 ,  0.45138319]), array([-0.62838086,  0.74562122,  0.77751738,  0.40192141, -0.67840122]), array([ 0.55538132, -0.51092129,  0.93449716, -0.18303999,  0.72668607]), array([0.2876619 , 0.73013271, 0.80466024, 0.10887494, 0.03074578]), array([-0.92135356, -0.94197426,  0.71324338, -0.32358757,  0.62510116]), array([ 0.03005995,  0.89502193,  0.16931196,  0.28087534, -0.50545035]), array([0.9663552 , 0.72308854, 0.29433077, 0.08974239, 0.1352653 ]), array([ 0.53373121, -0.13089479,  0.67239768, -0.39975276, -0.23101118]), array([-0.22152195, -0.19086917,  0.02142239, -0.38019464, -0.26674248]), array([-0.84224997, -0.01760476,  0.44309865, -0.33019494,  0.77861136]), array([ 0.86682847,  0.54829771, -0.26062489, -0.61566905,  0.85252666]), array([ 0.47792592, -0.98324208,  0.77676009, -0.85975578, -0.90673505]), array([-0.5851326 ,  0.54963445,  0.59682595,  0.17412202, -0.8502354 ]), array([-0.70250482,  0.50027641, -0.8545111 , -0.83335589, -0.65731616]), array([-0.10602957,  0.33592472, -0.28995039, -0.96446204, -0.08765614]), array([-0.90304102,  0.39099778, -0.43428191, -0.38686445,  0.53871583]), array([-0.48700378, -0.823681  ,  0.96322412, -0.3611304 , -0.23625434]), array([ 0.22788159,  0.20097466,  0.04048015, -0.90436678, -0.21410632]), array([ 0.59947685,  0.78189882, -0.26960304, -0.66084756, -0.38590763]), array([ 0.21362228,  0.738808  , -0.67144295, -0.90587273,  0.93617632]), array([ 0.77423794, -0.66507668, -0.52064548,  0.30728889, -0.38640403]), array([ 0.765331  ,  0.88335537,  0.62899993,  0.77674485, -0.00270708]), array([-0.7100644 ,  0.53077841,  0.23949163, -0.51111492, -0.88232557]), array([-0.84758173,  0.82415589,  0.85845201, -0.61576131,  0.68358779]), array([-0.66170454, -0.42224175, -0.84756836, -0.31593651, -0.52023188]), array([ 0.07974738,  0.18950669, -0.25810047, -0.13589622, -0.83249627]), array([-0.16827242,  0.62655035,  0.48507593,  0.34854167,  0.55387681]), array([ 0.71646883, -0.41552399,  0.4135555 ,  0.97619037, -0.92482205]), array([-0.84149232, -0.26667883,  0.79325858, -0.19021037, -0.76066799]), array([-0.69691206, -0.98333752, -0.60105818, -0.12106956, -0.44073322]), array([-0.7651285 ,  0.78968695, -0.52526819, -0.86479266, -0.09998232]), array([ 0.45303842, -0.24766611,  0.76170551,  0.64873169,  0.44698377]), array([-0.18431626,  0.58055568, -0.00169402,  0.41876882, -0.73420824]), array([-0.81961171,  0.80498095, -0.3837577 ,  0.52519974,  0.95923733]), array([ 0.98600213,  0.98832215,  0.8806346 , -0.05461773, -0.00851037]), array([-0.67612223,  0.2443358 ,  0.23830394, -0.17395365, -0.81115352]), array([ 0.5623    ,  0.89930644, -0.89456617, -0.45370868, -0.62877318]), array([-0.09401331, -0.43828667,  0.0658857 , -0.89096971, -0.73327181]), array([ 0.67066885, -0.67777839, -0.43187977, -0.69677793,  0.7854716 ]), array([-0.13272115,  0.41760116,  0.12922652,  0.5136334 , -0.25267634]), array([-0.48282948, -0.71818061,  0.76946369,  0.49271422,  0.94153474]), array([ 0.98425561, -0.74181436, -0.57637732, -0.71634129,  0.85187542]), array([ 0.74344933,  0.19871178,  0.86543348, -0.68260512,  0.89374511]), array([ 0.46462622,  0.09166664, -0.64804705, -0.09033101,  0.48536805]), array([-0.25176545,  0.6140206 ,  0.62030637, -0.19092476, -0.77339432]), array([ 0.8945004 , -0.92701659, -0.88248192, -0.99324016, -0.35570449]), array([-0.41160308,  0.08720818, -0.06204791,  0.35483701,  0.68305436]), array([-0.83621687,  0.94621657,  0.94325857,  0.37989762, -0.47201785]), array([ 0.91407139,  0.34962992, -0.75872206,  0.9534907 ,  0.58495993]), array([-0.37642495, -0.67570414,  0.4969288 ,  0.52867372,  0.49546267]), array([ 0.56254993, -0.84873554, -0.34647337,  0.61677655, -0.06658405]), array([-0.58109867,  0.52320965, -0.30338251, -0.69128768, -0.10217469]), array([ 0.47970601,  0.95517147,  0.54939506,  0.11790123, -0.973442  ]), array([-0.89240194,  0.16810094, -0.08543361, -0.45194033, -0.84734587]), array([ 0.68783215,  0.84748749,  0.13144455,  0.86953724, -0.12208544]), array([-0.62946287,  0.06474531, -0.99424563,  0.98111828,  0.61552755]), array([-0.10595785, -0.10483179,  0.37679233,  0.6642742 ,  0.38368474]), array([-0.98476737,  0.37820372, -0.04730213,  0.61961218,  0.56492645]), array([-0.93644511, -0.15640075, -0.14316236, -0.05706157, -0.71237111]), array([-0.59588677, -0.70505032,  0.23649082, -0.06016257,  0.64575745]), array([-0.64097727,  0.61216728,  0.09519387, -0.85583535, -0.88372513]), array([-0.90030548,  0.09631883,  0.82556741,  0.92703842,  0.0789823 ]), array([-0.33621128, -0.98665539,  0.35335194,  0.49096432,  0.28759811]), array([-0.85646087,  0.02594769, -0.95884399,  0.12256327,  0.98949328]), array([ 0.83991048,  0.23761111,  0.84043108,  0.25647074, -0.35623209]), array([ 0.95973148,  0.65045464, -0.39619617, -0.38296357,  0.49908882]), array([ 0.80540723,  0.11390471, -0.18646632,  0.27777106, -0.05920816]), array([-0.92269069, -0.70793536, -0.49133148,  0.62891509, -0.06072742]), array([-0.14364661,  0.55579049,  0.37466622,  0.4079244 , -0.65584558]), array([ 0.57956923, -0.85438125,  0.7023834 , -0.75462288, -0.15297156]), array([0.38825999, 0.88162731, 0.9569769 , 0.68409581, 0.19032854]), array([-0.43383103,  0.50449313, -0.92930329, -0.52915984,  0.09672907]), array([-0.44460759,  0.06871065,  0.31552762, -0.79757591,  0.30833919]), array([-0.20582867, -0.60010029,  0.36266476,  0.72730366,  0.70127392]), array([-0.20740463,  0.7021348 ,  0.94880985,  0.12080306,  0.70147313]), array([ 0.54815075,  0.70234812, -0.7672158 , -0.64048344, -0.85458118]), array([ 0.51247441, -0.15648594,  0.18054172,  0.3316009 ,  0.95953033]), array([-0.19107014,  0.64051846,  0.35542119,  0.58762587,  0.5142082 ]), array([-0.91474904, -0.35486169, -0.45954871, -0.89647729,  0.20225134]), array([-0.15411786, -0.1368516 , -0.35690489, -0.54735612, -0.7961232 ]), array([ 0.73439804,  0.08785034, -0.87053211,  0.12371878,  0.32276159]), array([ 0.91807551, -0.49993364, -0.92536048, -0.89627152, -0.31684466]), array([0.8991604 , 0.4675974 , 0.87697079, 0.14897987, 0.72261379]), array([-0.40805093,  0.79516746, -0.36833355,  0.34003735, -0.12947498]), array([-0.66803041, -0.64292896, -0.29401293, -0.04650224, -0.2009339 ]), array([-0.87320603, -0.1049267 ,  0.96263361,  0.97193519,  0.09558647]), array([ 0.00615815,  0.01851542, -0.02967849, -0.71106272,  0.04251592]), array([ 0.41070664,  0.85231311,  0.36482805, -0.1064853 ,  0.57889097]), array([-0.4868786 ,  0.5930857 , -0.91933224,  0.993505  , -0.19463038]), array([-0.21414921, -0.6645213 ,  0.88764591, -0.17111123,  0.00675038]), array([-0.64464125,  0.61653329, -0.41578173, -0.19278753, -0.5679861 ]), array([-0.99614344, -0.39702083, -0.69370974, -0.65974642, -0.72388272]), array([ 0.73011437,  0.32270876,  0.03119828, -0.85259312,  0.33804432]), array([-0.81468448,  0.90670818, -0.21427051, -0.94886966, -0.36886185]), array([-0.17186132,  0.89160194, -0.61128   ,  0.2937784 , -0.41517289]), array([ 0.81655217, -0.92633804,  0.74257674, -0.94871063, -0.7298961 ]), array([ 0.42964511, -0.33088452, -0.0806695 , -0.98623395,  0.45047876]), array([-0.94576221, -0.39934958, -0.23459144, -0.59183753, -0.66566288]), array([ 0.1450993 , -0.90039244, -0.27210801,  0.63592495, -0.2304509 ]), array([ 0.35153499, -0.57545973, -0.56176302,  0.68274964,  0.46893575]), array([ 0.49379886,  0.95494458, -0.51338744, -0.67669309,  0.41760994]), array([-0.52212637,  0.52518009, -0.53517653, -0.82186071,  0.37843301]), array([ 0.55807846, -0.22039316,  0.23384459,  0.21933111,  0.91666035]), array([ 0.73638916,  0.83691697, -0.40386741, -0.49401345,  0.38989072]), array([-0.00706391, -0.71650257,  0.15623657, -0.40125405, -0.07156901]), array([-0.37911663,  0.30152017, -0.73773572,  0.64566748,  0.57132874]), array([-0.70533757,  0.67634522,  0.34204391,  0.61110154,  0.15714931]), array([ 0.17734464,  0.60216794,  0.86393515, -0.47962008, -0.11810035]), array([-0.81416616, -0.53711203,  0.09488103,  0.28241891, -0.33166633]), array([-0.37587129, -0.4704247 , -0.22507796, -0.29760736, -0.49831779]), array([ 0.87949574,  0.52393672,  0.40363244, -0.56428247,  0.9567972 ]), array([ 0.39496085,  0.00739926, -0.34713678,  0.52249118, -0.59886332]), array([-0.91506202,  0.75224421,  0.91760794,  0.75261406,  0.7017765 ]), array([-0.03783487,  0.4643502 ,  0.66273061,  0.86819768, -0.33244218]), array([-0.7723316 ,  0.48096763,  0.13717551, -0.01003485, -0.59396255]), array([ 0.72088025, -0.70233937, -0.963645  , -0.07425076,  0.34562658]), array([-0.91731487, -0.83358178, -0.88723966, -0.95716002,  0.7240321 ]), array([ 0.90207286, -0.83634823,  0.48064744, -0.61436642, -0.89436896]), array([ 0.01192766,  0.05923989, -0.72602937, -0.34363104,  0.24599141]), array([-0.21281826,  0.16951079,  0.77259135, -0.59685939, -0.85955496]), array([ 0.09613967,  0.78010991,  0.9576068 , -0.75898466, -0.23509485]), array([-0.42330338,  0.26199966, -0.70655586, -0.57532085,  0.83540153]), array([ 0.55438038,  0.42062993,  0.14602678,  0.48585672, -0.7402471 ]), array([-0.35611699, -0.74727043, -0.83699013, -0.91845473,  0.99900949]), array([ 0.76438107, -0.31512823, -0.88069306,  0.91170526,  0.70801014]), array([ 0.03896746,  0.52592705,  0.09604056, -0.1213908 , -0.10500208]), array([-0.51862337, -0.81445221, -0.75240159, -0.22171673, -0.31919484]), array([-0.62786549, -0.64103217,  0.29008222,  0.26242963, -0.07421957]), array([-0.62080071,  0.85122052,  0.61502782, -0.09333434,  0.68777174]), array([ 0.48166782, -0.04963199,  0.11859772, -0.38836825,  0.47242168]), array([ 0.0433051 , -0.92168723,  0.36543043, -0.1468713 ,  0.79704591]), array([-0.10922709, -0.28483073, -0.58599843,  0.73113548,  0.15293433]), array([-0.26901518,  0.65556553,  0.33001752,  0.62272512,  0.57587299]), array([ 0.71288531, -0.56690557,  0.62912559,  0.77739743,  0.1498895 ]), array([ 0.76450262, -0.43334659, -0.93865734,  0.37358961, -0.92550084]), array([-0.24466655,  0.4212442 ,  0.28625883,  0.64811602,  0.6180362 ]), array([-0.66231818, -0.71191798, -0.20195027,  0.63886347, -0.11378138]), array([-0.02505968, -0.51109815, -0.67445288, -0.0642749 , -0.26038548]), array([-0.7988116 ,  0.94772793, -0.70500651,  0.75320404, -0.31378164]), array([ 0.3147693 ,  0.50435791, -0.98309993, -0.67463236,  0.99085582]), array([-0.10189958,  0.40542562,  0.6599044 ,  0.81699372,  0.24193769]), array([ 0.40257147, -0.98865023, -0.00525192, -0.1270883 , -0.47766186]), array([0.64401366, 0.25926991, 0.42843597, 0.29832922, 0.89457745]), array([ 0.61385512, -0.08082364,  0.5538722 ,  0.24273943,  0.20485039]), array([ 0.22602672, -0.10734611,  0.90308577, -0.29577383,  0.51117338]), array([ 0.05164651, -0.93131649, -0.04014746, -0.0756102 , -0.46183692]), array([ 0.15132898, -0.49289804, -0.01008424,  0.09743905, -0.31990612]), array([0.85321792, 0.312419  , 0.31753991, 0.30379403, 0.39900796]), array([-0.1094871 ,  0.52168766,  0.85545358, -0.5174021 ,  0.84989558]), array([-0.8202138 ,  0.9631567 , -0.91675472,  0.92339089, -0.05472532]), array([-0.86309019,  0.01414796,  0.24905743, -0.47986939, -0.18596023]), array([ 0.20948778, -0.40392803, -0.34335951,  0.97817657,  0.22777819]), array([-0.33353479, -0.67054348,  0.94300921, -0.55211472,  0.60131054]), array([-0.28526028,  0.71836218,  0.1359743 , -0.72848286, -0.05405103]), array([ 0.74394585,  0.6240521 , -0.38729088,  0.51575984,  0.46734234]), array([ 0.38507542, -0.57016292,  0.10086966, -0.65281204, -0.07071136]), array([ 0.90787567, -0.80177995, -0.28865106, -0.51553451,  0.45410478]), array([ 0.77798656, -0.4745396 ,  0.47017029,  0.15351277,  0.2511054 ]), array([-0.89503968, -0.02034272,  0.56169801,  0.78316577,  0.37821118]), array([-0.42938314,  0.8625996 ,  0.13625015, -0.55059844,  0.70178216]), array([ 0.27439033, -0.82161237,  0.17371793, -0.41158145, -0.38350195]), array([-0.17581542,  0.68098143,  0.05603046,  0.88784068,  0.95010025]), array([-0.62694604, -0.68330179, -0.69782809, -0.45325561, -0.5496039 ]), array([ 0.15675042,  0.17077546,  0.55789051,  0.76403073, -0.58425616]), array([-0.68246052, -0.7643905 ,  0.82805511, -0.21004777, -0.27274733]), array([-0.65424116, -0.73448804,  0.90119933,  0.16661399,  0.71799219]), array([-0.34839074,  0.10144109,  0.37138536,  0.06233169,  0.75767422]), array([-0.86191327,  0.51626101,  0.93111993,  0.45813519,  0.55195832]), array([ 0.91074986, -0.49227519, -0.82856012,  0.88733776, -0.06884155]), array([-0.62926417, -0.75868277,  0.47000598, -0.48075947,  0.6424411 ]), array([ 0.98661847,  0.29988696,  0.1942861 ,  0.60693589, -0.70521415]), array([-0.36345724, -0.02628552, -0.78623409,  0.13393618, -0.61680316]), array([-0.54914995,  0.02038735, -0.59108485, -0.08283407,  0.04506038]), array([ 0.75561157, -0.13953509,  0.89311738, -0.95310537, -0.95532846]), array([ 0.35665615, -0.94099529,  0.70145121,  0.25013879,  0.8289026 ]), array([-0.10082736, -0.6724839 , -0.75081648,  0.52382984,  0.3574439 ]), array([ 0.53683393, -0.85598503,  0.4562465 ,  0.05347598, -0.63269403]), array([-0.62605798, -0.28491356,  0.47828066,  0.91012024, -0.70844022]), array([-0.30027652,  0.15950062,  0.34051806, -0.77931994,  0.0767849 ]), array([-0.54869338,  0.64481076,  0.19559949,  0.38897882,  0.21768135]), array([ 0.29949997, -0.22590635, -0.82310643,  0.2500206 ,  0.68947784]), array([ 0.95501112, -0.42148882,  0.86004612,  0.75482722, -0.29761008]), array([-0.01751503,  0.40864783,  0.75952605, -0.70686534, -0.93528752]), array([-0.0681347 , -0.26218962,  0.79473389,  0.20377042,  0.15895593]), array([ 0.34518018,  0.96416786,  0.48339879, -0.66500338, -0.86409291]), array([-0.50817756,  0.31841084,  0.83790114,  0.2974252 , -0.25889329]), array([ 0.77041719, -0.43998369,  0.42506116,  0.69332282, -0.62445287]), array([-0.70098919,  0.02073359, -0.83661484,  0.45888634,  0.08607834]), array([ 0.24610279, -0.35689691,  0.68709378,  0.19985883, -0.83683085]), array([ 0.34088889,  0.39941504,  0.94185428, -0.34133233,  0.75345891]), array([ 0.06823266, -0.28223916, -0.32452876, -0.6012692 ,  0.3976452 ]), array([-0.49204107,  0.37923582,  0.32566866, -0.25533484,  0.65405339]), array([-0.82469515,  0.76452571,  0.0574675 , -0.54243397,  0.55210421]), array([-0.98148653, -0.07547163, -0.70782055, -0.19174605,  0.7098291 ]), array([ 0.64333818, -0.95858914, -0.68265003,  0.97714284, -0.07087671]), array([-0.73837483, -0.16086882, -0.12570843,  0.45624323, -0.73077891]), array([-0.54762218,  0.37093815, -0.02446625,  0.6329384 ,  0.75776647]), array([ 0.70221004, -0.60637775,  0.13451228,  0.29288481, -0.4439393 ]), array([-0.12227067, -0.89488706, -0.77001433, -0.16071258, -0.29641696]), array([-0.79069997, -0.39414407, -0.10253622,  0.4691602 , -0.17619598]), array([ 0.25074815, -0.81699134, -0.18938358, -0.80527318,  0.90596763]), array([ 0.16024551,  0.27019193,  0.92251267,  0.14061063, -0.35741921]), array([ 0.34360629, -0.99967881,  0.06420686,  0.67929077, -0.22548251]), array([-0.4679163 ,  0.32598629,  0.64388213, -0.9232495 ,  0.8756849 ])] 462\n",
      "\n",
      " labels =  [-1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "f = open('data5D_train.csv','r')\n",
    "lines = f.readlines()\n",
    "values=[]\n",
    "labels=[]\n",
    "for l in lines:\n",
    "    item=l.split()\n",
    "    item.pop()\n",
    "    values.append(np.array(item, dtype=\"float\"))\n",
    "    labels.append(float(l.split().pop()))\n",
    "print(\"values = \", values, len(values))\n",
    "print(\"\\n labels = \", labels)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "[ 0.07553725 -0.19610503  0.06159207 -0.64933547  0.46879926] \n",
      "errors =  36\n",
      "Epoch 1\n",
      "\n",
      "[ 0.04944294 -0.08274571  0.09759394 -0.78882254  0.58306662] \n",
      "errors =  15\n",
      "Epoch 2\n",
      "\n",
      "[ 0.08581935 -0.19627008  0.08388106 -0.84210278  0.69415417] \n",
      "errors =  16\n",
      "Epoch 3\n",
      "\n",
      "[ 0.06385658 -0.23748753  0.10822428 -0.92079196  0.65192312] \n",
      "errors =  7\n",
      "Epoch 4\n",
      "\n",
      "[ 0.07674028 -0.21314461  0.14657809 -0.94966029  0.7265409 ] \n",
      "errors =  7\n",
      "Epoch 5\n",
      "\n",
      "[ 0.07077806 -0.31468461  0.04861564 -0.94942633  0.72677687] \n",
      "errors =  3\n",
      "Epoch 6\n",
      "\n",
      "[ 0.10634375 -0.23809138  0.16590574 -1.0016462   0.80897133] \n",
      "errors =  12\n",
      "Epoch 7\n",
      "\n",
      "[ 0.11822039 -0.24443213  0.07951917 -1.10111029  0.77299692] \n",
      "errors =  5\n",
      "Epoch 8\n",
      "\n",
      "[ 0.10776175 -0.25871756  0.16291208 -1.06925642  0.7929193 ] \n",
      "errors =  1\n",
      "Epoch 9\n",
      "\n",
      "[ 0.13098428 -0.26811984  0.18152499 -1.11281104  0.83445889] \n",
      "errors =  8\n",
      "Epoch 10\n",
      "\n",
      "[ 0.08954705 -0.28991838  0.1510188  -1.17425096  0.78915271] \n",
      "errors =  4\n",
      "Epoch 11\n",
      "\n",
      "[ 0.10016474 -0.35937881  0.18060153 -1.17022045  0.83323132] \n",
      "errors =  6\n",
      "Epoch 12\n",
      "\n",
      "[ 0.12864248 -0.32762266  0.17653876 -1.17279081  0.87245566] \n",
      "errors =  4\n",
      "Epoch 13\n",
      "\n",
      "[ 0.12864248 -0.32762266  0.17653876 -1.17279081  0.87245566] \n",
      "errors =  0\n"
     ]
    }
   ],
   "source": [
    "p2=Perceptron(len(values[0]))          \n",
    "p2.learn(values, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values =  [array([-0.21072208, -0.79501808,  0.28437907,  0.86837059,  0.73060236]), array([-0.12111626,  0.60824274, -0.47358205,  0.69620996,  0.21952921]), array([-0.23219499, -0.62105231,  0.05503385,  0.48291495,  0.8759104 ]), array([-0.59664385,  0.82638592,  0.35032913,  0.84496857,  0.66859734]), array([ 0.46476267,  0.8978245 ,  0.75454346,  0.20200565, -0.1353804 ]), array([-0.78494979, -0.60999804,  0.29379305, -0.8845752 , -0.71955901]), array([-0.29776664, -0.38832218,  0.88802089, -0.77137815,  0.64237691]), array([-0.64676409, -0.6279182 , -0.3026547 ,  0.31399474,  0.36810387]), array([ 0.73956971, -0.34440171,  0.88305262,  0.24552222, -0.60348933]), array([-0.44282619,  0.75906882,  0.90602738,  0.04138422, -0.59254111]), array([ 0.593805  , -0.41387575,  0.14167655,  0.06919212, -0.43647877]), array([ 0.23357398,  0.75990753, -0.66117702, -0.08285438, -0.09631611]), array([ 0.22716695,  0.53400283, -0.9568675 , -0.40931456,  0.48318165]), array([-0.40282615,  0.29867592,  0.2898277 , -0.64994401, -0.64278564]), array([ 0.32350392,  0.99816322, -0.83050165,  0.27879267,  0.82276005]), array([ 0.68036637,  0.47784936, -0.32226832,  0.9161375 , -0.49692859]), array([-0.52039711,  0.0589753 , -0.13664326,  0.42770273, -0.60053963]), array([-0.63240129, -0.22621903,  0.78179963, -0.28840948,  0.07163177]), array([-0.37901283, -0.57218072,  0.87346909, -0.20421944,  0.39488019]), array([ 0.56458829,  0.55557141, -0.70902545, -0.73670312,  0.58835561]), array([-0.78796617,  0.39111251,  0.38533465,  0.93835734, -0.18080539]), array([ 0.98858344,  0.9048458 ,  0.92435586, -0.12690144,  0.77405103]), array([-0.16352644, -0.6866783 ,  0.04081859,  0.14136002,  0.5252732 ]), array([ 0.14698831, -0.41211546, -0.39831655, -0.57616649, -0.19886519]), array([-0.03554649, -0.91925279,  0.84375738, -0.03090127, -0.42073269]), array([-0.6874917 ,  0.26957806, -0.12522154, -0.46220807, -0.04001457]), array([-0.64771257, -0.68478481, -0.0207135 , -0.81694799,  0.33257536]), array([ 0.3339873 , -0.84603488,  0.49728449, -0.05521146,  0.59621594]), array([-0.85239091,  0.44512076,  0.74132181,  0.98372952, -0.50356598]), array([ 0.83354527,  0.38557253,  0.58110842, -0.97737187,  0.52831336]), array([-0.52301011,  0.60271519,  0.99790543, -0.99491859,  0.60997541]), array([-0.96002173, -0.02254594,  0.40396244,  0.90731505, -0.1283012 ]), array([-0.2617324 , -0.81364251, -0.24372044, -0.56983957, -0.05206477]), array([-0.15902244, -0.8652233 ,  0.60998576,  0.85010301,  0.21049197]), array([-0.40659572, -0.59721773, -0.08337011, -0.02292577, -0.49258436]), array([-0.83789047, -0.96067434, -0.18712074,  0.03354587,  0.29752138]), array([-0.19390428, -0.34747883,  0.67932765,  0.30002136,  0.14812372]), array([-0.88317874, -0.58137457,  0.9227387 ,  0.21181696, -0.30647078]), array([0.66725276, 0.46208342, 0.00854323, 0.66274078, 0.71934508]), array([-0.38317968, -0.70737752, -0.40390972,  0.60632201, -0.41239466]), array([-0.57305719, -0.3214432 ,  0.73788816, -0.0944642 ,  0.44353855]), array([-0.74761441,  0.25455878, -0.47108278, -0.25650701,  0.88125079]), array([ 0.87421448, -0.1205296 ,  0.17377011, -0.4305763 , -0.70197227]), array([-0.88974516, -0.89075354,  0.19824244, -0.65000236,  0.28081082]), array([ 0.02133812,  0.33675893, -0.96354575,  0.50621545,  0.89747172]), array([ 0.18041423, -0.97902724, -0.70663158,  0.73439982, -0.32148357]), array([ 0.22455351, -0.89423448, -0.04221302, -0.49372608, -0.11281503]), array([ 0.60359862,  0.74557928, -0.00725418, -0.67304164, -0.07826843]), array([ 0.56233156, -0.10422016,  0.08273139,  0.47079896, -0.69718094]), array([ 0.70370058,  0.14542337, -0.85817668, -0.61043767,  0.85884441]), array([ 0.42440928,  0.16089888,  0.5073565 , -0.57660747, -0.29291478]), array([-0.64884851,  0.24517228,  0.08915391,  0.49207934, -0.60346016]), array([ 0.02239053, -0.07295574, -0.10425667,  0.04537549, -0.56881837]), array([-0.07417759,  0.25294729,  0.95706317,  0.64874916,  0.85008646]), array([ 0.83028432,  0.66706229,  0.76614704, -0.47622745,  0.40583439]), array([ 0.66739241,  0.67958595, -0.77033433, -0.69278173,  0.63404656]), array([-0.86297069,  0.20978497,  0.40797126,  0.64579634,  0.0903676 ]), array([-0.89233635, -0.0567538 , -0.29453789,  0.47464338,  0.72613551]), array([-0.3895963 ,  0.04577438, -0.63176262, -0.97952863, -0.3836081 ]), array([-0.20787888,  0.39508831,  0.22770771, -0.81031566,  0.26382559]), array([-0.21116927, -0.6512767 , -0.82650551,  0.66414155, -0.42939267]), array([ 0.91097208, -0.58760856,  0.37027828, -0.80676345, -0.69055637]), array([ 0.29815691, -0.3830236 , -0.90804864, -0.05491437,  0.32164306]), array([ 0.13727175, -0.35292675, -0.70190643,  0.85432935, -0.42839914]), array([ 0.87065744,  0.70998252, -0.43103224,  0.42419433,  0.13127233]), array([-0.19094069, -0.235653  ,  0.60367505,  0.75742483,  0.7302567 ]), array([-0.50107096, -0.82750322, -0.76781642, -0.29555432, -0.75289436]), array([-0.60088187,  0.04106457, -0.66268704, -0.0074169 , -0.90990037]), array([ 0.37487292, -0.81414125, -0.47620909,  0.93018791,  0.7897874 ]), array([-0.79888794, -0.63745622,  0.15698947,  0.76157827, -0.90843505]), array([ 0.757973  , -0.26481692, -0.74205714, -0.00167795, -0.44506214]), array([ 0.20721486, -0.54816591,  0.52819933,  0.92142203, -0.36223625]), array([ 0.07682199,  0.07618828, -0.26940792,  0.17284762, -0.4935095 ]), array([ 0.76569728,  0.03958652,  0.13891385, -0.81552378, -0.79973207]), array([ 0.5580589 ,  0.20059402,  0.84967271,  0.76108261, -0.4478313 ]), array([-0.9913035 , -0.40492855,  0.23457219, -0.34729328,  0.82388824]), array([-0.68433653, -0.28842717, -0.14124311, -0.61925465, -0.24837427]), array([-0.26181531, -0.10713082, -0.08492101,  0.48357139,  0.24966116]), array([ 0.84390426, -0.07791267,  0.25504179, -0.87361658, -0.08493644]), array([ 0.80925529, -0.33863129,  0.51721605, -0.64015308, -0.77232768]), array([ 0.56441564,  0.82030907,  0.23140161, -0.64417556, -0.73381762]), array([ 0.39639352,  0.87922859, -0.59605783, -0.19131763, -0.080413  ]), array([-0.16387799,  0.7427953 , -0.95405891,  0.8774957 , -0.58677922]), array([-0.69861871, -0.28750585,  0.85991493, -0.27434109,  0.31428501]), array([ 0.18638651,  0.80378919, -0.48840305, -0.20396053, -0.29739631]), array([-0.63327327, -0.46869742, -0.77906791, -0.24898783,  0.80371265]), array([ 0.94881168, -0.52797687,  0.75544037, -0.92346926, -0.89036159]), array([-0.64796823, -0.87529778,  0.41860402, -0.83878718,  0.47079263]), array([ 0.27862065,  0.03640727, -0.17017872, -0.1466398 , -0.70030508]), array([-0.53629649, -0.84904093, -0.12689545, -0.0527353 ,  0.80148355]), array([-0.26598418,  0.37813026,  0.44604151, -0.48186351,  0.11764164]), array([ 0.81743714, -0.58809527,  0.10483189, -0.75934688, -0.11797608]), array([-0.89780506,  0.87049613, -0.9692678 ,  0.34516776, -0.97182142]), array([-0.06731801, -0.13760649,  0.25354004,  0.5819464 , -0.04324888]), array([-0.09321804, -0.72530192,  0.43555702,  0.99125239, -0.20199031]), array([-0.37701202, -0.73872574, -0.6339259 , -0.21159259, -0.55871085]), array([-0.7648886 , -0.26534155, -0.92255153,  0.82553775,  0.30673906]), array([ 0.28069558,  0.62929385, -0.48086693, -0.97979339,  0.77238678]), array([ 0.86038791,  0.8029848 ,  0.27649984,  0.05037369, -0.20809635]), array([-0.48532185, -0.93171714,  0.43067386,  0.00441842, -0.68799757]), array([ 0.83762979, -0.976486  ,  0.63740557, -0.13796736,  0.73210407]), array([ 0.04575866,  0.79348135, -0.70899207, -0.05388626, -0.8099287 ]), array([-0.13791936, -0.52177434,  0.10637986, -0.86935444,  0.27504608]), array([ 0.41679917, -0.3060904 ,  0.43746274,  0.04279006, -0.37602631]), array([-0.61008836, -0.83808209,  0.23164254,  0.67059171,  0.35879996]), array([-0.77993929,  0.37838154,  0.93216124, -0.15830904, -0.87607358]), array([ 0.63663175, -0.50962928,  0.84880643, -0.76798398, -0.75342476]), array([ 0.38495247, -0.08332637,  0.78365282,  0.3154081 ,  0.6536693 ]), array([-0.13240259, -0.01718617, -0.28613766, -0.43614463,  0.95545013]), array([ 0.94007032, -0.46966986,  0.80671498, -0.6597186 , -0.78984445]), array([-0.56325761, -0.80056241,  0.78874239,  0.33308709,  0.98311192]), array([-0.62639779,  0.74198391, -0.01872167,  0.85519617,  0.23837456]), array([ 0.16939875, -0.15002941, -0.58168351, -0.41727889, -0.99042891]), array([ 0.11006554,  0.73143362, -0.10046706, -0.37287977, -0.34066707]), array([-0.91190003, -0.14390053, -0.89716636,  0.41461249,  0.54857526]), array([ 0.51419363, -0.36485289,  0.72072868,  0.29314783,  0.05534215]), array([ 0.04130471,  0.29059776,  0.38128608,  0.2267114 , -0.08503895]), array([ 0.79852489, -0.63457388,  0.53202598,  0.66860879, -0.52107606]), array([-0.98442831, -0.92009204,  0.92405817,  0.02536962,  0.2924567 ]), array([-0.25606298, -0.33258274, -0.62782942,  0.73796496, -0.67339304]), array([ 0.98406999, -0.8693782 ,  0.30267638,  0.03757941, -0.43567351]), array([-0.92406349,  0.38721772,  0.98759462,  0.37550204,  0.05903584]), array([-0.52089562,  0.66181927, -0.84100652,  0.42347099,  0.6686425 ]), array([-0.00129397,  0.2859635 , -0.94438637,  0.81725441,  0.74128636]), array([-0.11614005, -0.11636209,  0.81602855,  0.79578526,  0.60689347]), array([ 0.92204614,  0.20550562,  0.20462031, -0.00554684, -0.98608469]), array([-0.76435533, -0.22304507,  0.05726532,  0.38624486,  0.62860485]), array([ 0.86920817,  0.39265135, -0.84519678, -0.63489404,  0.93456342]), array([ 0.86244992, -0.04096595,  0.099461  , -0.84597577,  0.70792173]), array([ 0.23302797, -0.65678687, -0.20913574, -0.59962109,  0.92467722]), array([ 0.26933886,  0.27462348, -0.42958934, -0.21877469, -0.21724513]), array([-0.13739422, -0.99591585, -0.72040908, -0.09243457,  0.39387911]), array([ 0.74179349,  0.26531146, -0.53124835, -0.11707404, -0.75086192]), array([ 0.81183973,  0.40975774,  0.65617984, -0.56680921,  0.87667956]), array([-0.48685555,  0.66476301,  0.48551806, -0.30373622, -0.47922678]), array([ 0.59194978, -0.16228779,  0.97208529,  0.20993953, -0.92035619]), array([ 0.49127159,  0.87713597, -0.1258821 ,  0.48283767,  0.55562184]), array([-0.75516368,  0.93386083, -0.542299  , -0.84897307, -0.6709893 ]), array([ 0.3242354 ,  0.89309364, -0.23826305, -0.12341243,  0.89040175]), array([ 0.71381582, -0.64957462,  0.82416821,  0.39786692, -0.85315504]), array([ 0.93840692,  0.29963077,  0.92466507, -0.57010749, -0.82260359]), array([-0.56657825, -0.26068058, -0.02461241, -0.7426305 ,  0.12795671]), array([ 0.34081653, -0.29556609, -0.93196097, -0.60265202,  0.60712032]), array([ 0.21622042,  0.27338717, -0.85096776, -0.17065525, -0.45348254]), array([ 0.68264557, -0.8333387 ,  0.50584226,  0.0941006 , -0.74501586]), array([-0.9628625 ,  0.27051334,  0.65477002,  0.11185695, -0.79971669]), array([0.2758361 , 0.52742643, 0.29436283, 0.52148872, 0.07647666]), array([ 0.10913027, -0.07372222,  0.36515484,  0.02660224,  0.30310352]), array([ 0.21529959,  0.54258374, -0.45649001,  0.44203533, -0.34852509]), array([-0.58237388,  0.31174041,  0.41077876,  0.24799536, -0.57677442]), array([ 0.97130382, -0.74328546, -0.47285096, -0.32489533,  0.74246554]), array([ 0.77611051,  0.09969506, -0.01603916,  0.43784358,  0.6593024 ]), array([-0.46379606, -0.7766529 , -0.35465384, -0.33046617,  0.64176965]), array([-0.26022461, -0.99806144,  0.13858644, -0.9738455 ,  0.0281593 ]), array([ 0.31487555,  0.73926673,  0.43197024, -0.31873841,  0.68253837]), array([ 0.67130658,  0.51967132,  0.40415393, -0.01847876,  0.59212258]), array([ 0.25665546, -0.27290349, -0.30544482, -0.46326606,  0.9715836 ]), array([ 0.98747814, -0.99591834, -0.87263851,  0.69346553, -0.98745885]), array([ 0.98954974,  0.47101697,  0.59947048, -0.95489892, -0.87561404]), array([ 0.22670224,  0.1625077 , -0.48499114,  0.0489505 , -0.28800287]), array([ 0.47591014,  0.28489349, -0.37234386, -0.4833152 ,  0.67331316]), array([0.91854984, 0.14732583, 0.20096562, 0.08728473, 0.44845632]), array([-0.56149119, -0.730063  ,  0.67021627,  0.02273453,  0.85328528]), array([ 0.28314748, -0.34413671,  0.44867166,  0.6827243 , -0.22128846]), array([-0.16847919,  0.1344946 ,  0.18816237,  0.95898115, -0.3739232 ]), array([0.45893466, 0.27649353, 0.21373703, 0.99136064, 0.95357168]), array([ 0.06552949, -0.67255137,  0.16234855,  0.24681045, -0.23325368]), array([ 0.6233442 , -0.04527301, -0.31099549,  0.70816292,  0.16593398]), array([-0.88505684, -0.0097214 ,  0.8233959 , -0.30424466, -0.42756327]), array([ 0.04473965, -0.9326413 ,  0.27679408,  0.84903175, -0.16647578]), array([-0.20396524, -0.74397211, -0.69374116, -0.70598327,  0.87623566]), array([-0.7317657 , -0.46244891, -0.19182937,  0.36606864,  0.28245026]), array([-0.74830491,  0.03707728,  0.36269556,  0.01210571,  0.16307996]), array([ 0.59147623, -0.04915187,  0.69755248, -0.77218505, -0.24142516]), array([ 0.85485652, -0.0556058 ,  0.39213836,  0.55966857,  0.99409734]), array([ 0.3064938 , -0.41009388, -0.78307914,  0.11662857, -0.34173972]), array([ 0.64847295, -0.85572467, -0.91789535, -0.39651048,  0.33684503]), array([-0.08764377, -0.22500604, -0.38418156, -0.94001047,  0.4172429 ]), array([-0.11169415,  0.62246937, -0.75046936,  0.65935889,  0.21473317]), array([ 0.8074874 , -0.64189843,  0.47347918, -0.68053752, -0.08498725]), array([-0.68635307, -0.00397266,  0.85325511,  0.60011463,  0.28867656]), array([-0.69897057, -0.98402279, -0.52798648, -0.3078766 ,  0.65259359]), array([ 0.48320966,  0.04044124, -0.53193741,  0.46194143, -0.45726992]), array([ 0.21995493, -0.02327624,  0.68945455,  0.43042972,  0.4498723 ]), array([-0.04018463, -0.23588519, -0.58608528,  0.99331621, -0.11926599]), array([-0.86596769,  0.10642496, -0.89506795, -0.49056087, -0.32618221]), array([-0.27901974,  0.01831084, -0.79598717, -0.37343288, -0.66595406]), array([ 0.5347465 ,  0.54760007, -0.83704145, -0.327415  , -0.4815041 ]), array([-0.55061973, -0.95451571,  0.36425999, -0.30529253,  0.79974353]), array([-0.76346317,  0.94812531, -0.19451894,  0.19334189, -0.9097948 ]), array([-0.85442508,  0.34053446, -0.85280908, -0.50652813,  0.35200036]), array([ 0.62828606,  0.41333111, -0.86169065, -0.15452753, -0.22874998]), array([-0.0765548 ,  0.98902945,  0.59617521,  0.09594763, -0.22184141]), array([ 0.32244876, -0.33557157, -0.70051887, -0.07199472, -0.74636519]), array([ 0.48728533, -0.922463  , -0.97433568, -0.38372269,  0.405437  ]), array([-0.61741384, -0.14985066, -0.51857552, -0.52758129, -0.73109037]), array([ 0.43465209,  0.07480575, -0.71074896, -0.47218883, -0.05842627]), array([-0.93031174, -0.73559255, -0.01412473,  0.33248028, -0.08921653]), array([ 0.92243147,  0.06396235, -0.45342245,  0.62498195, -0.90089682]), array([ 0.64320111, -0.32760671, -0.83331006,  0.16314165, -0.07013509]), array([-0.35247923,  0.50475973,  0.23766498, -0.22436332, -0.78263605]), array([-0.90639886,  0.23094034,  0.5194672 , -0.99253779,  0.0161395 ]), array([ 0.93645104, -0.388913  ,  0.05881371,  0.97454805, -0.73366649]), array([-0.51522386,  0.20144621, -0.55827445, -0.95144712,  0.69458175]), array([ 0.68956363,  0.89859472,  0.17487847, -0.35333173, -0.91646569]), array([-0.43252782, -0.35999022, -0.83346337, -0.16709417, -0.24417288]), array([-0.32532921, -0.04175309, -0.06644195,  0.73732919, -0.94792553]), array([-0.05776907,  0.19356422, -0.29660441, -0.57741609,  0.79758072]), array([-0.9836682 ,  0.55729175, -0.28449201,  0.35878078, -0.14945814]), array([-0.74785731, -0.13508731,  0.52217358,  0.93950758, -0.05757843]), array([-0.57773058,  0.99625928, -0.51736735, -0.23034164, -0.76404072]), array([ 0.03014879, -0.01555466,  0.92201311, -0.67596249,  0.4332707 ]), array([-0.24124823,  0.29352935,  0.26533022, -0.88426876, -0.05077305]), array([-0.63883688,  0.92161004, -0.70217847, -0.49508659,  0.37076561]), array([-0.48265244,  0.65451248,  0.1446828 ,  0.06350857, -0.47826579]), array([ 0.59649458,  0.52483453,  0.11246772, -0.27191049, -0.41190873]), array([-0.60846228, -0.62499818,  0.67376032,  0.02637774,  0.3366319 ]), array([-0.82588061,  0.83846992,  0.47517091, -0.18951163,  0.35315267]), array([ 0.354875  ,  0.92039581, -0.88485137,  0.70961837,  0.78922352]), array([ 0.62471011, -0.58941682, -0.52265494,  0.76802527, -0.98019674]), array([ 0.50606788,  0.88794279,  0.79403644, -0.81913846, -0.02469612]), array([-0.16187217,  0.83614244,  0.0955076 ,  0.63624186, -0.28114219]), array([ 0.69565955, -0.80977229, -0.08926859,  0.3418076 ,  0.59847033]), array([-0.14658334, -0.81509606, -0.88545454, -0.51623533,  0.50910777]), array([ 0.17846276, -0.24113053, -0.27545197, -0.09454442, -0.81526555]), array([ 0.66974747, -0.12976526,  0.80451725,  0.32543637, -0.06521721]), array([-0.34315056,  0.21214349,  0.68255877,  0.53055977,  0.05911915]), array([-0.2278788 , -0.85409589,  0.73905214, -0.62519505, -0.40550455]), array([ 0.77646001, -0.6382989 , -0.19039299,  0.76687692,  0.7540907 ]), array([-0.28798334, -0.01672996, -0.87366173, -0.9017316 , -0.60852495]), array([-0.72282775, -0.01849952,  0.41107679,  0.60935658,  0.45956284]), array([-0.21779153,  0.76215573, -0.87754874,  0.19425871,  0.17481762]), array([ 0.61513633,  0.03877735,  0.11972749, -0.27576495, -0.40807282]), array([ 0.88163148, -0.22041101, -0.63000668,  0.35147271, -0.33365585]), array([-0.29221383, -0.54626124, -0.78095091,  0.17004032, -0.42085715]), array([ 0.65962277, -0.47085712,  0.65958116,  0.67774319,  0.58139113]), array([-0.96970553, -0.10147138, -0.16431126, -0.96905439, -0.8202821 ]), array([ 0.81887399,  0.04903627, -0.91549578,  0.66773867,  0.39246704]), array([-0.19684289, -0.92733712, -0.65839365,  0.87356904, -0.77428438]), array([-0.14473365,  0.92533241,  0.3251855 ,  0.36065253,  0.691887  ]), array([-0.44943593, -0.77159447,  0.14121577, -0.50685582,  0.08142273]), array([-0.92665209,  0.01113371, -0.5851129 , -0.69130762, -0.99267215]), array([ 0.72634923, -0.44107092, -0.35053689, -0.72460665, -0.8754573 ]), array([-0.53558016,  0.89915075, -0.24825342,  0.03441632,  0.08372383]), array([-0.22287918, -0.0570576 , -0.96258008, -0.40333064,  0.42724911]), array([ 0.02368382, -0.51015633,  0.73237429,  0.46680574,  0.84072077]), array([ 0.74508508,  0.45140753,  0.50680014, -0.4467347 ,  0.51867859]), array([-0.34512742, -0.58922495,  0.92430857,  0.42927445, -0.01287955]), array([ 0.33380347,  0.42340911,  0.60863566, -0.07934105, -0.57933027]), array([-0.70707341,  0.88955653,  0.38321553,  0.05367293, -0.27351175]), array([-0.056242  ,  0.80087896, -0.11891643,  0.43029928, -0.04227224]), array([ 0.26910907, -0.12382375, -0.5845758 , -0.41445576, -0.22046628]), array([ 0.28821432, -0.91324543, -0.49112121,  0.82430161, -0.45546603]), array([-0.72199989, -0.65412111, -0.67158181, -0.67134312, -0.5664906 ]), array([-0.87903198,  0.09400889,  0.69066635, -0.16954522, -0.34711959]), array([ 0.18753478, -0.14915339,  0.40404981, -0.88956542,  0.31348419]), array([-0.29072824, -0.55787185, -0.24687391,  0.4784147 ,  0.22632106]), array([ 0.49700572,  0.63108183, -0.90913857,  0.89025523, -0.08318582]), array([-0.80006641, -0.72239399, -0.01381957, -0.20760429, -0.4436197 ]), array([ 0.99981658, -0.11148364,  0.24485703, -0.31958229, -0.54675803]), array([0.58374758, 0.87690964, 0.91164216, 0.15850613, 0.43639593]), array([-0.07294616,  0.5376867 ,  0.20289893, -0.95012693, -0.60496554]), array([ 0.69274592, -0.12649879,  0.69062712,  0.3008163 ,  0.05220584]), array([ 0.80958247,  0.43480797,  0.74672685, -0.02588583,  0.25211614]), array([-0.23091977,  0.4108541 , -0.21882955,  0.14093946, -0.49682326]), array([-0.11823797, -0.25865232, -0.08472974, -0.82696873, -0.58278765]), array([-0.01252328,  0.90437011,  0.67879104, -0.68248071, -0.75754829]), array([-0.24955424,  0.41822893, -0.85763373, -0.83397173,  0.34318714]), array([ 0.5555393 , -0.63611626,  0.32739635, -0.80131573, -0.1875053 ]), array([-0.56445357, -0.95576537, -0.15189858,  0.79843788,  0.56072677]), array([ 0.48422333, -0.11954337, -0.23675836,  0.07288153,  0.56828689]), array([-0.37358555,  0.02452275, -0.85283353, -0.84681817,  0.39924601]), array([ 0.99531788,  0.88646062,  0.97008239, -0.7171894 ,  0.89317397]), array([ 0.61046373,  0.29571239, -0.286872  , -0.84030575, -0.65801599]), array([-0.97731112, -0.17155753, -0.08658087,  0.49850195,  0.2500317 ]), array([-0.45716901,  0.01716697,  0.10550568, -0.57413124, -0.16614399]), array([0.67915231, 0.43913959, 0.57006471, 0.0122894 , 0.50342219]), array([-0.66558358,  0.19699286,  0.66212885,  0.76541656, -0.22780022]), array([ 0.9692923 , -0.78544754,  0.27268381,  0.02199486,  0.19155529]), array([-0.6847586 ,  0.81273206,  0.4775489 ,  0.29046292,  0.69760705]), array([-0.59410388, -0.64519195,  0.29777887,  0.44973426,  0.03214872]), array([ 0.30695845, -0.6155131 ,  0.95515886,  0.62823901, -0.49244953]), array([-0.13371405, -0.68526148, -0.85617352, -0.74386898, -0.19636759]), array([-0.04053831, -0.65018475,  0.77514397, -0.17296451,  0.19431872]), array([-0.31139983,  0.48775473, -0.23262484,  0.89435625,  0.32782563]), array([ 0.34527718, -0.00305669,  0.09629714, -0.08959332,  0.37468277]), array([ 0.53327641, -0.34949267, -0.68901014, -0.54364068,  0.37245924]), array([ 0.23687208, -0.111752  , -0.87620608,  0.36819215, -0.90568501]), array([-0.67740607, -0.84820831,  0.42647386, -0.95629084, -0.74876819]), array([-0.30883857,  0.19092451,  0.54843573, -0.20711122,  0.83107688]), array([-0.42577433,  0.93272227,  0.24529919,  0.3099762 , -0.11754854]), array([-0.75859223,  0.52243752,  0.55778779,  0.83119526,  0.23458287]), array([-0.81722619, -0.50207122, -0.75446399, -0.84078063,  0.83507907]), array([ 0.09336593, -0.59559084,  0.72393   , -0.56627568, -0.60156003]), array([ 0.57140535,  0.71251482,  0.85659311, -0.34423922, -0.58391649]), array([ 0.34877882, -0.77396199, -0.07496155,  0.60331976, -0.20435091]), array([-0.32812565,  0.71290125,  0.16503312, -0.07288177, -0.33481084]), array([-0.00128529,  0.18140923, -0.7387753 ,  0.32692694,  0.11529064]), array([-0.69345163, -0.87175172,  0.41516626, -0.13698238,  0.45187202]), array([-0.3936927 ,  0.49613676,  0.12102021,  0.854941  ,  0.55891339]), array([ 0.32648663, -0.80141963, -0.42247659,  0.38913036, -0.22679687]), array([-0.21845013, -0.68427185, -0.48840053, -0.29719771,  0.67078278]), array([-0.4441939 ,  0.04122942,  0.99969275, -0.74292377,  0.69912583]), array([ 0.29952717,  0.62672989, -0.06648321,  0.2918619 , -0.12675557]), array([-0.32833097, -0.00955299,  0.89434899,  0.70310853,  0.42538845]), array([-0.68362153,  0.74308551, -0.99436653,  0.27643424,  0.95655272]), array([-0.91555441, -0.80301131, -0.19334256, -0.29575049, -0.52364956]), array([ 0.27440945, -0.51191869,  0.47206212, -0.16150335,  0.5341136 ]), array([-0.32043282,  0.19318414, -0.27095809,  0.18659855, -0.09294893]), array([-0.80719293,  0.06359902,  0.22978205, -0.3510897 , -0.70629136]), array([-0.25120893,  0.83006977, -0.02265604, -0.04481958, -0.13064986]), array([ 0.85891269,  0.06803451, -0.61134045,  0.86944852, -0.63492539]), array([-0.29032457,  0.94596035,  0.95033476,  0.03018975, -0.16506277]), array([-0.32073943,  0.25689828,  0.99633344,  0.20866275, -0.43737529]), array([ 0.66498318, -0.28080633,  0.42926465,  0.39558984, -0.44625535]), array([ 0.33400755, -0.91312381,  0.60209985, -0.23646227,  0.18677764]), array([-0.03175238, -0.66385753, -0.77644095, -0.83990963,  0.68434313]), array([-0.49301787, -0.61930834, -0.73415466,  0.9402297 , -0.63499168]), array([-0.54961884,  0.4384844 ,  0.70213701,  0.74734035, -0.8896812 ]), array([ 0.16788603, -0.0416931 ,  0.10516032, -0.42316793, -0.16451911]), array([ 0.42010679, -0.85703577, -0.60115589,  0.13569449,  0.38852706]), array([-0.42567682, -0.5114889 ,  0.02071099, -0.44313104, -0.19366715]), array([ 0.4262682 ,  0.22486609,  0.86229753, -0.18302723, -0.64008433]), array([0.79770421, 0.44300328, 0.1932904 , 0.50797096, 0.07245943]), array([ 0.54988988, -0.49340178, -0.31965549, -0.93438863,  0.9316053 ]), array([-0.74370109,  0.6599833 , -0.21083483, -0.84800788,  0.50028399]), array([ 0.91181619,  0.72340334, -0.74279784, -0.46411888, -0.65930238]), array([ 0.94626145, -0.95091961, -0.21419641, -0.87632082,  0.69679039]), array([-0.35810088,  0.80228633, -0.52931247, -0.7078654 , -0.78579277]), array([-0.1251342 ,  0.63291888, -0.78030028,  0.84827102, -0.04825206]), array([ 0.27531668,  0.15440683,  0.47161946, -0.04589094,  0.49015105]), array([-0.68246458,  0.98085852, -0.10086766, -0.83883888, -0.6555357 ]), array([-0.98555516, -0.46789852, -0.81401796, -0.45553282,  0.38657412]), array([-0.46700791,  0.4121275 , -0.0313955 , -0.06718531, -0.33440656]), array([-0.73734448,  0.63485664, -0.09545211, -0.1953803 , -0.85267213]), array([-0.17715862,  0.80452601, -0.94308743, -0.72485913,  0.74863798]), array([ 0.76080867, -0.27650446, -0.80964631, -0.81423814,  0.78165053]), array([-0.83089947, -0.75076286, -0.13139696,  0.78212678,  0.03433389]), array([ 0.98678648, -0.67141684, -0.90396034, -0.97334453, -0.37598007]), array([ 0.95072923, -0.1544158 , -0.18465487,  0.20087173,  0.62184929]), array([-0.55968838, -0.78636606, -0.65889724, -0.71567681,  0.45617003]), array([ 0.20008884,  0.8066471 ,  0.2892532 , -0.62531606,  0.5191494 ]), array([-0.59962293, -0.53614642,  0.31945282, -0.93538297, -0.13267916]), array([-0.00989133, -0.31074649, -0.4395583 , -0.27957765, -0.39135721]), array([-0.2001963 , -0.30055971,  0.74977841, -0.2163818 , -0.76265058]), array([-0.61710714,  0.69438507, -0.67675888,  0.17894227,  0.26344524]), array([ 0.75126299, -0.56986277,  0.50669913, -0.20388768, -0.57735364]), array([ 0.82333428,  0.17631852,  0.17742623,  0.45323677, -0.11972907]), array([ 0.90189285,  0.90484633, -0.92892393,  0.54723749,  0.75882764]), array([-0.78064075, -0.15998931, -0.9607853 , -0.31112418, -0.75634025]), array([-0.07688379, -0.40107781, -0.12132631, -0.12698345,  0.56522251]), array([ 0.5478785 , -0.2552979 , -0.43144159,  0.87741282, -0.32233567]), array([-0.34958018, -0.03978744,  0.59208353, -0.10498168,  0.31613315]), array([ 0.81509429, -0.12034437, -0.89504061,  0.71290542,  0.88173888]), array([-0.19869917, -0.63299146, -0.80718127, -0.10253452, -0.16124922]), array([ 0.15933784,  0.91102597, -0.20424902,  0.08264215, -0.53753251]), array([ 0.22843501,  0.10919245, -0.09533757, -0.5469933 ,  0.56289179]), array([-0.08397252,  0.51885048,  0.78836893,  0.94684919,  0.91120334]), array([-0.66349927, -0.11487462, -0.1740308 , -0.98236266, -0.09075106]), array([-0.54887522, -0.91687437, -0.31159763,  0.0992097 , -0.39809306]), array([-0.54349252, -0.94417021,  0.35952256,  0.88848834,  0.46348549]), array([ 0.40781716,  0.33619711,  0.93272714,  0.22557492, -0.9822225 ]), array([-0.15210732, -0.66961489,  0.77614544, -0.50359552,  0.07375271]), array([-0.57042767,  0.10514713,  0.16619755, -0.28298145, -0.69898781]), array([-0.9027867 ,  0.12178126,  0.91101885, -0.09764691,  0.48223061]), array([ 0.39470402,  0.86569771,  0.82317324,  0.44481843, -0.15717168]), array([-8.91148080e-01,  1.88378163e-04, -3.65579682e-01, -8.44579455e-01,\n",
      "        8.88433102e-01]), array([0.98592045, 0.93839498, 0.87565791, 0.52522175, 0.41478665]), array([ 0.47114558,  0.84094165, -0.72262927,  0.9937125 ,  0.66445424]), array([ 0.74788397, -0.13166963,  0.99200901, -0.3645217 ,  0.04792022]), array([ 0.20537145, -0.03076004, -0.92108795,  0.39054225,  0.46954502]), array([ 0.94735135,  0.04978722,  0.96187448, -0.72773693, -0.35757361]), array([-0.91308565, -0.75126207, -0.5608629 ,  0.04114233, -0.8724196 ]), array([-0.33431517,  0.73625408, -0.08969387,  0.77881585, -0.69662354]), array([-0.36527482,  0.73529776,  0.82370983,  0.09542537, -0.08220993]), array([ 0.76616932, -0.32344967,  0.01232167,  0.18305286,  0.31393795]), array([-0.54517573, -0.36380333, -0.69136683,  0.84594334, -0.27183781]), array([ 0.22788804, -0.6735665 ,  0.62402774,  0.46089584, -0.43238624]), array([-0.99982401,  0.05498466,  0.59919772,  0.07568699,  0.23138267]), array([-0.70821156, -0.48252387, -0.18767393,  0.28899568, -0.73022176]), array([ 0.69170426, -0.35695363,  0.01785035, -0.88984956, -0.09393273]), array([-0.13028381,  0.84858572,  0.1583943 ,  0.05471649,  0.45185586]), array([ 0.23754028, -0.94073735,  0.32958771,  0.41591499, -0.44792831]), array([-0.88230988, -0.40443263,  0.6042506 , -0.50708482,  0.48341358]), array([ 0.88639434, -0.46375898,  0.86275747, -0.45572787,  0.46267018]), array([ 0.57211693,  0.69812318, -0.93509285,  0.24003026, -0.98704765]), array([-0.0681333 ,  0.17459274, -0.25228096,  0.70581713, -0.34472393]), array([-0.33815716, -0.48519857,  0.79571768, -0.23204188, -0.95940873]), array([-0.61913434, -0.98157017,  0.05101596,  0.64652891,  0.2201194 ]), array([ 0.20909481, -0.94390256,  0.60910653, -0.22617276,  0.73566169]), array([ 0.61921547,  0.17243441, -0.21950341,  0.77368973,  0.87499601]), array([ 0.60286562,  0.90112503, -0.09975371, -0.58524889,  0.7887855 ]), array([0.52172289, 0.02736498, 0.11084348, 0.16980149, 0.74076474]), array([ 0.5976132 , -0.75195752,  0.61664809, -0.82638095,  0.10140747]), array([ 0.18081632, -0.84140666, -0.82080318,  0.72102712, -0.78484819]), array([ 0.10153664, -0.6302041 ,  0.49057055,  0.50791879,  0.90696194]), array([-0.65672469, -0.23090554, -0.36517073,  0.62439286,  0.05292836]), array([-0.45712653,  0.96481246, -0.70408908, -0.07220091, -0.48805718]), array([-0.14632191, -0.79693696, -0.22239548,  0.40910275, -0.73921911]), array([-0.58186886, -0.64397073,  0.30178955, -0.87512032,  0.54396776]), array([-0.72000577,  0.09064197,  0.51644833, -0.58845955, -0.18486312]), array([-0.28891945, -0.8903881 , -0.67928416,  0.81570486, -0.55339673]), array([-0.26214213,  0.28997987,  0.29356601, -0.00826597,  0.99330299]), array([-0.93780514, -0.95092847,  0.8895204 ,  0.33121389,  0.2151684 ]), array([-0.49647725, -0.57338746, -0.2101838 ,  0.73443902,  0.8187933 ]), array([ 0.10642712, -0.38752513,  0.83118618,  0.2394249 ,  0.54391672]), array([ 0.70903888,  0.09163173,  0.40279595, -0.86524663, -0.40536352]), array([ 0.52085045,  0.15942801, -0.86260279,  0.22713794,  0.90937061]), array([-0.00761744, -0.17386004, -0.29502312, -0.27724649,  0.6839406 ]), array([-0.07637983, -0.73037593,  0.97590017, -0.22162515,  0.29465599]), array([ 0.95813862, -0.70822012,  0.77559636,  0.15471297,  0.38993156]), array([ 0.91839645,  0.54758885, -0.48919916, -0.77104941,  0.12468425]), array([-0.06324935,  0.6285523 ,  0.46117717, -0.05469538,  0.47892316]), array([-0.2848835 ,  0.07060588, -0.34642499,  0.48285302, -0.87689428]), array([-0.90904571,  0.34770198, -0.29570931, -0.26075108,  0.73467121]), array([-0.37438889, -0.53367672,  0.89911961,  0.81949188,  0.20472114]), array([-0.97029978,  0.27211335,  0.29045299, -0.68416123,  0.41272829]), array([ 0.19649957, -0.10304279,  0.36144344,  0.09112909,  0.07602034]), array([-0.51738386, -0.80423877,  0.15372803, -0.36906996,  0.78695206]), array([-0.16965305,  0.74154698,  0.39257641, -0.37337202, -0.88416903]), array([ 0.04681212, -0.13250538, -0.79580029,  0.87635445, -0.26121316]), array([-0.51556746,  0.52771168, -0.28943297, -0.39804235, -0.14571387]), array([ 0.82812571,  0.25157957,  0.58767602,  0.86348619, -0.60705176]), array([-0.25110102, -0.74591601, -0.19149414, -0.67090333,  0.76802209]), array([-0.24500936, -0.65525429,  0.00460868,  0.29668308,  0.96604288]), array([-0.06519232, -0.96114234, -0.23488367,  0.52401364,  0.08375787]), array([-0.06538134, -0.41989294,  0.29981383,  0.85114126, -0.45880798]), array([-0.58170361,  0.48034915,  0.38940176, -0.40894261,  0.65062321]), array([ 0.86970735, -0.06936374, -0.31804656, -0.33537321, -0.15367598]), array([-0.54899832, -0.34818371, -0.89759575, -0.45007004,  0.97374072]), array([-0.40362005, -0.83113994, -0.42976631,  0.31032327,  0.69522399]), array([ 0.10923823, -0.2733235 ,  0.84913497,  0.5423317 ,  0.17738329]), array([-0.77557947,  0.68191884,  0.48424104,  0.21461226,  0.20689433]), array([-0.43547927, -0.846677  , -0.15663245,  0.64940082, -0.41289187]), array([-0.98001578,  0.38333693, -0.62679572,  0.10486399, -0.62983633]), array([ 0.38583622, -0.30486263, -0.85059581,  0.49934115, -0.48243422]), array([-0.03062364,  0.62659531, -0.80209406, -0.21295471,  0.36655247]), array([0.22489697, 0.66402984, 0.9583008 , 0.95979144, 0.74472968]), array([ 0.78656142, -0.21523868,  0.22008679,  0.52616085,  0.99309616]), array([-0.92096772,  0.45059971, -0.21103019,  0.89563801,  0.14344006]), array([ 0.79666665, -0.76388694, -0.74427427,  0.86642848, -0.92310526]), array([-0.70193066,  0.07402652, -0.29969593,  0.85897298,  0.64520885]), array([ 0.50338305,  0.89693319,  0.59182561, -0.17199278,  0.33222804]), array([-0.41609152, -0.75356375,  0.22839609,  0.69936183,  0.81162413]), array([-0.18928939,  0.47304033, -0.60196724,  0.49830542,  0.44762381]), array([ 0.71171251,  0.60605595, -0.79362844,  0.40776343, -0.36109961]), array([-0.30941492, -0.97719888, -0.88720874, -0.19214125, -0.15107056]), array([ 0.13301249, -0.85727736,  0.66232726, -0.00103038, -0.6212953 ]), array([ 0.6040148 , -0.69150169, -0.38717036,  0.20533277, -0.12169707]), array([-0.42354771, -0.95701767, -0.92466401, -0.42877405,  0.08914227]), array([ 0.56009491,  0.58599168, -0.34258117,  0.4473364 , -0.35183086]), array([ 0.81396451, -0.13635607, -0.82100371,  0.38129875,  0.48276383]), array([-0.28488747, -0.23330188,  0.69964622, -0.16570167,  0.26364505]), array([-0.70362656, -0.30904413,  0.12050448, -0.32420566,  0.84733789]), array([-0.1188034 ,  0.45245554, -0.28463905, -0.90566217, -0.24749591]), array([ 0.78599418, -0.93969179, -0.24586821, -0.05150218,  0.32341797]), array([-0.35132614,  0.17135209,  0.31069921,  0.42389191, -0.38706541]), array([ 0.98268865, -0.71750484, -0.04151376, -0.59969444,  0.81878813]), array([ 0.8150283 , -0.92463509,  0.06528731, -0.91783952, -0.02310608]), array([ 0.6210676 ,  0.00717717, -0.21834593, -0.36968095, -0.91581677]), array([-0.64269708,  0.84341309,  0.95217726, -0.13381438,  0.83653301]), array([ 0.02710715, -0.57069915, -0.60084541, -0.45905642, -0.73560863]), array([-0.44644111,  0.33153243, -0.04759622,  0.59308517,  0.47431711]), array([ 0.27036055, -0.09988157,  0.68642954, -0.56194094, -0.55312108]), array([-0.96230515,  0.07519828,  0.94564365, -0.05246137,  0.6495676 ]), array([ 0.05710823,  0.77588791,  0.61908249, -0.28830795, -0.68485263]), array([-0.53557357,  0.87745437, -0.6177616 ,  0.89725329,  0.7151515 ]), array([ 0.41189133,  0.43612457, -0.29902284,  0.29220458, -0.5324298 ]), array([-0.67986958,  0.31314412, -0.66754316,  0.62176168, -0.77782044]), array([0.64954601, 0.84420554, 0.14861023, 0.73913704, 0.98839505]), array([-0.78264925,  0.50616639,  0.38482553,  0.46401361,  0.08795351]), array([-0.59681276,  0.02846043,  0.25574474,  0.75169254, -0.49864016]), array([ 0.49231051, -0.72570602,  0.91692711, -0.16763268, -0.95883628]), array([-0.74887946, -0.67450574,  0.96838279, -0.70769351, -0.28355645]), array([ 0.74725013,  0.11370918, -0.67333228,  0.64720459, -0.61314869]), array([-0.42234577,  0.94277973, -0.38436912,  0.25094566,  0.81985865]), array([ 0.13726875, -0.14644619, -0.29291298, -0.74767518,  0.24966398]), array([-0.10295889, -0.74097543, -0.8334027 ,  0.95595454,  0.12158564]), array([-0.66903514, -0.00541094, -0.15379053, -0.4705048 ,  0.67524684]), array([ 0.81948498,  0.97519455, -0.84973906, -0.83268434, -0.72887821]), array([-0.44303822, -0.12122357,  0.56182697, -0.63546652,  0.86385584]), array([-0.8786063 , -0.14132021,  0.78222951, -0.10128356,  0.48527332]), array([-0.7979985 , -0.83922217, -0.72205007, -0.68224388, -0.93539294]), array([-0.58866919, -0.03864697,  0.8391856 , -0.32449099,  0.81078654]), array([ 0.80503081, -0.51113813, -0.84678039,  0.83904717, -0.36021499]), array([-0.79697083,  0.16499071, -0.00637142,  0.02020882, -0.02190623]), array([ 0.0993775 , -0.56667143, -0.10886088, -0.49120804, -0.88747812]), array([-0.78021471,  0.35217867, -0.29107453,  0.90762168, -0.42985089]), array([ 0.0673751 , -0.31541987, -0.78245366, -0.68492267,  0.23567349]), array([-0.28960944, -0.15619135,  0.90507601,  0.59775244, -0.09617161]), array([0.67907071, 0.00613763, 0.47191729, 0.65510653, 0.4179075 ]), array([ 0.03854587,  0.86104938,  0.23411752, -0.25446469, -0.72048086])]\n"
     ]
    }
   ],
   "source": [
    "f = open('data5D_test.csv','r')\n",
    "lines = f.readlines()\n",
    "tests=[]\n",
    "for l in lines:\n",
    "    item=l.split()\n",
    "    tests.append(np.array(item, dtype=\"float\"))\n",
    "print(\"values = \", tests)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for sample 0 is -1\n",
      "The prediction for sample 1 is -1\n",
      "The prediction for sample 2 is 1\n",
      "The prediction for sample 3 is -1\n",
      "The prediction for sample 4 is -1\n",
      "The prediction for sample 5 is 1\n",
      "The prediction for sample 6 is 1\n",
      "The prediction for sample 7 is -1\n",
      "The prediction for sample 8 is -1\n",
      "The prediction for sample 9 is -1\n",
      "The prediction for sample 10 is -1\n",
      "The prediction for sample 11 is -1\n",
      "The prediction for sample 12 is 1\n",
      "The prediction for sample 13 is -1\n",
      "The prediction for sample 14 is -1\n",
      "The prediction for sample 15 is -1\n",
      "The prediction for sample 16 is -1\n",
      "The prediction for sample 17 is 1\n",
      "The prediction for sample 18 is 1\n",
      "The prediction for sample 19 is 1\n",
      "The prediction for sample 20 is -1\n",
      "The prediction for sample 21 is 1\n",
      "The prediction for sample 22 is 1\n",
      "The prediction for sample 23 is 1\n",
      "The prediction for sample 24 is -1\n",
      "The prediction for sample 25 is 1\n",
      "The prediction for sample 26 is 1\n",
      "The prediction for sample 27 is 1\n",
      "The prediction for sample 28 is -1\n",
      "The prediction for sample 29 is 1\n",
      "The prediction for sample 30 is 1\n",
      "The prediction for sample 31 is -1\n",
      "The prediction for sample 32 is 1\n",
      "The prediction for sample 33 is -1\n",
      "The prediction for sample 34 is -1\n",
      "The prediction for sample 35 is 1\n",
      "The prediction for sample 36 is -1\n",
      "The prediction for sample 37 is -1\n",
      "The prediction for sample 38 is -1\n",
      "The prediction for sample 39 is -1\n",
      "The prediction for sample 40 is 1\n",
      "The prediction for sample 41 is 1\n",
      "The prediction for sample 42 is -1\n",
      "The prediction for sample 43 is 1\n",
      "The prediction for sample 44 is -1\n",
      "The prediction for sample 45 is -1\n",
      "The prediction for sample 46 is 1\n",
      "The prediction for sample 47 is 1\n",
      "The prediction for sample 48 is -1\n",
      "The prediction for sample 49 is 1\n",
      "The prediction for sample 50 is 1\n",
      "The prediction for sample 51 is -1\n",
      "The prediction for sample 52 is -1\n",
      "The prediction for sample 53 is -1\n",
      "The prediction for sample 54 is 1\n",
      "The prediction for sample 55 is 1\n",
      "The prediction for sample 56 is -1\n",
      "The prediction for sample 57 is -1\n",
      "The prediction for sample 58 is 1\n",
      "The prediction for sample 59 is 1\n",
      "The prediction for sample 60 is -1\n",
      "The prediction for sample 61 is 1\n",
      "The prediction for sample 62 is 1\n",
      "The prediction for sample 63 is -1\n",
      "The prediction for sample 64 is -1\n",
      "The prediction for sample 65 is -1\n",
      "The prediction for sample 66 is -1\n",
      "The prediction for sample 67 is -1\n",
      "The prediction for sample 68 is -1\n",
      "The prediction for sample 69 is -1\n",
      "The prediction for sample 70 is -1\n",
      "The prediction for sample 71 is -1\n",
      "The prediction for sample 72 is -1\n",
      "The prediction for sample 73 is 1\n",
      "The prediction for sample 74 is -1\n",
      "The prediction for sample 75 is 1\n",
      "The prediction for sample 76 is 1\n",
      "The prediction for sample 77 is -1\n",
      "The prediction for sample 78 is 1\n",
      "The prediction for sample 79 is 1\n",
      "The prediction for sample 80 is -1\n",
      "The prediction for sample 81 is -1\n",
      "The prediction for sample 82 is -1\n",
      "The prediction for sample 83 is 1\n",
      "The prediction for sample 84 is -1\n",
      "The prediction for sample 85 is 1\n",
      "The prediction for sample 86 is 1\n",
      "The prediction for sample 87 is 1\n",
      "The prediction for sample 88 is -1\n",
      "The prediction for sample 89 is 1\n",
      "The prediction for sample 90 is 1\n",
      "The prediction for sample 91 is 1\n",
      "The prediction for sample 92 is -1\n",
      "The prediction for sample 93 is -1\n",
      "The prediction for sample 94 is -1\n",
      "The prediction for sample 95 is -1\n",
      "The prediction for sample 96 is -1\n",
      "The prediction for sample 97 is 1\n",
      "The prediction for sample 98 is -1\n",
      "The prediction for sample 99 is -1\n",
      "The prediction for sample 100 is 1\n",
      "The prediction for sample 101 is -1\n",
      "The prediction for sample 102 is 1\n",
      "The prediction for sample 103 is -1\n",
      "The prediction for sample 104 is -1\n",
      "The prediction for sample 105 is -1\n",
      "The prediction for sample 106 is 1\n",
      "The prediction for sample 107 is 1\n",
      "The prediction for sample 108 is 1\n",
      "The prediction for sample 109 is 1\n",
      "The prediction for sample 110 is 1\n",
      "The prediction for sample 111 is -1\n",
      "The prediction for sample 112 is -1\n",
      "The prediction for sample 113 is -1\n",
      "The prediction for sample 114 is -1\n",
      "The prediction for sample 115 is -1\n",
      "The prediction for sample 116 is -1\n",
      "The prediction for sample 117 is -1\n",
      "The prediction for sample 118 is 1\n",
      "The prediction for sample 119 is -1\n",
      "The prediction for sample 120 is -1\n",
      "The prediction for sample 121 is -1\n",
      "The prediction for sample 122 is -1\n",
      "The prediction for sample 123 is -1\n",
      "The prediction for sample 124 is -1\n",
      "The prediction for sample 125 is -1\n",
      "The prediction for sample 126 is -1\n",
      "The prediction for sample 127 is 1\n",
      "The prediction for sample 128 is 1\n",
      "The prediction for sample 129 is 1\n",
      "The prediction for sample 130 is -1\n",
      "The prediction for sample 131 is 1\n",
      "The prediction for sample 132 is -1\n",
      "The prediction for sample 133 is 1\n",
      "The prediction for sample 134 is -1\n",
      "The prediction for sample 135 is -1\n",
      "The prediction for sample 136 is -1\n",
      "The prediction for sample 137 is -1\n",
      "The prediction for sample 138 is 1\n",
      "The prediction for sample 139 is -1\n",
      "The prediction for sample 140 is -1\n",
      "The prediction for sample 141 is 1\n",
      "The prediction for sample 142 is 1\n",
      "The prediction for sample 143 is -1\n",
      "The prediction for sample 144 is -1\n",
      "The prediction for sample 145 is -1\n",
      "The prediction for sample 146 is -1\n",
      "The prediction for sample 147 is 1\n",
      "The prediction for sample 148 is -1\n",
      "The prediction for sample 149 is -1\n",
      "The prediction for sample 150 is 1\n",
      "The prediction for sample 151 is -1\n",
      "The prediction for sample 152 is 1\n",
      "The prediction for sample 153 is 1\n",
      "The prediction for sample 154 is 1\n",
      "The prediction for sample 155 is 1\n",
      "The prediction for sample 156 is 1\n",
      "The prediction for sample 157 is -1\n",
      "The prediction for sample 158 is 1\n",
      "The prediction for sample 159 is -1\n",
      "The prediction for sample 160 is 1\n",
      "The prediction for sample 161 is 1\n",
      "The prediction for sample 162 is 1\n",
      "The prediction for sample 163 is -1\n",
      "The prediction for sample 164 is -1\n",
      "The prediction for sample 165 is -1\n",
      "The prediction for sample 166 is -1\n",
      "The prediction for sample 167 is -1\n",
      "The prediction for sample 168 is -1\n",
      "The prediction for sample 169 is -1\n",
      "The prediction for sample 170 is 1\n",
      "The prediction for sample 171 is -1\n",
      "The prediction for sample 172 is -1\n",
      "The prediction for sample 173 is 1\n",
      "The prediction for sample 174 is 1\n",
      "The prediction for sample 175 is -1\n",
      "The prediction for sample 176 is 1\n",
      "The prediction for sample 177 is 1\n",
      "The prediction for sample 178 is -1\n",
      "The prediction for sample 179 is 1\n",
      "The prediction for sample 180 is -1\n",
      "The prediction for sample 181 is 1\n",
      "The prediction for sample 182 is -1\n",
      "The prediction for sample 183 is -1\n",
      "The prediction for sample 184 is -1\n",
      "The prediction for sample 185 is -1\n",
      "The prediction for sample 186 is -1\n",
      "The prediction for sample 187 is -1\n",
      "The prediction for sample 188 is 1\n",
      "The prediction for sample 189 is -1\n",
      "The prediction for sample 190 is 1\n",
      "The prediction for sample 191 is -1\n",
      "The prediction for sample 192 is -1\n",
      "The prediction for sample 193 is -1\n",
      "The prediction for sample 194 is 1\n",
      "The prediction for sample 195 is -1\n",
      "The prediction for sample 196 is 1\n",
      "The prediction for sample 197 is -1\n",
      "The prediction for sample 198 is -1\n",
      "The prediction for sample 199 is -1\n",
      "The prediction for sample 200 is -1\n",
      "The prediction for sample 201 is 1\n",
      "The prediction for sample 202 is -1\n",
      "The prediction for sample 203 is 1\n",
      "The prediction for sample 204 is -1\n",
      "The prediction for sample 205 is -1\n",
      "The prediction for sample 206 is -1\n",
      "The prediction for sample 207 is 1\n",
      "The prediction for sample 208 is -1\n",
      "The prediction for sample 209 is -1\n",
      "The prediction for sample 210 is -1\n",
      "The prediction for sample 211 is 1\n",
      "The prediction for sample 212 is 1\n",
      "The prediction for sample 213 is 1\n",
      "The prediction for sample 214 is -1\n",
      "The prediction for sample 215 is -1\n",
      "The prediction for sample 216 is 1\n",
      "The prediction for sample 217 is 1\n",
      "The prediction for sample 218 is -1\n",
      "The prediction for sample 219 is -1\n",
      "The prediction for sample 220 is 1\n",
      "The prediction for sample 221 is -1\n",
      "The prediction for sample 222 is 1\n",
      "The prediction for sample 223 is 1\n",
      "The prediction for sample 224 is -1\n",
      "The prediction for sample 225 is -1\n",
      "The prediction for sample 226 is -1\n",
      "The prediction for sample 227 is 1\n",
      "The prediction for sample 228 is -1\n",
      "The prediction for sample 229 is 1\n",
      "The prediction for sample 230 is -1\n",
      "The prediction for sample 231 is -1\n",
      "The prediction for sample 232 is -1\n",
      "The prediction for sample 233 is -1\n",
      "The prediction for sample 234 is -1\n",
      "The prediction for sample 235 is -1\n",
      "The prediction for sample 236 is 1\n",
      "The prediction for sample 237 is -1\n",
      "The prediction for sample 238 is -1\n",
      "The prediction for sample 239 is -1\n",
      "The prediction for sample 240 is 1\n",
      "The prediction for sample 241 is -1\n",
      "The prediction for sample 242 is 1\n",
      "The prediction for sample 243 is -1\n",
      "The prediction for sample 244 is 1\n",
      "The prediction for sample 245 is 1\n",
      "The prediction for sample 246 is 1\n",
      "The prediction for sample 247 is -1\n",
      "The prediction for sample 248 is -1\n",
      "The prediction for sample 249 is -1\n",
      "The prediction for sample 250 is -1\n",
      "The prediction for sample 251 is 1\n",
      "The prediction for sample 252 is -1\n",
      "The prediction for sample 253 is 1\n",
      "The prediction for sample 254 is -1\n",
      "The prediction for sample 255 is 1\n",
      "The prediction for sample 256 is -1\n",
      "The prediction for sample 257 is -1\n",
      "The prediction for sample 258 is -1\n",
      "The prediction for sample 259 is -1\n",
      "The prediction for sample 260 is -1\n",
      "The prediction for sample 261 is 1\n",
      "The prediction for sample 262 is -1\n",
      "The prediction for sample 263 is 1\n",
      "The prediction for sample 264 is -1\n",
      "The prediction for sample 265 is 1\n",
      "The prediction for sample 266 is -1\n",
      "The prediction for sample 267 is 1\n",
      "The prediction for sample 268 is 1\n",
      "The prediction for sample 269 is -1\n",
      "The prediction for sample 270 is 1\n",
      "The prediction for sample 271 is 1\n",
      "The prediction for sample 272 is 1\n",
      "The prediction for sample 273 is 1\n",
      "The prediction for sample 274 is -1\n",
      "The prediction for sample 275 is 1\n",
      "The prediction for sample 276 is 1\n",
      "The prediction for sample 277 is -1\n",
      "The prediction for sample 278 is 1\n",
      "The prediction for sample 279 is -1\n",
      "The prediction for sample 280 is -1\n",
      "The prediction for sample 281 is -1\n",
      "The prediction for sample 282 is 1\n",
      "The prediction for sample 283 is 1\n",
      "The prediction for sample 284 is -1\n",
      "The prediction for sample 285 is 1\n",
      "The prediction for sample 286 is 1\n",
      "The prediction for sample 287 is -1\n",
      "The prediction for sample 288 is 1\n",
      "The prediction for sample 289 is 1\n",
      "The prediction for sample 290 is -1\n",
      "The prediction for sample 291 is -1\n",
      "The prediction for sample 292 is 1\n",
      "The prediction for sample 293 is 1\n",
      "The prediction for sample 294 is -1\n",
      "The prediction for sample 295 is -1\n",
      "The prediction for sample 296 is -1\n",
      "The prediction for sample 297 is -1\n",
      "The prediction for sample 298 is 1\n",
      "The prediction for sample 299 is -1\n",
      "The prediction for sample 300 is -1\n",
      "The prediction for sample 301 is 1\n",
      "The prediction for sample 302 is 1\n",
      "The prediction for sample 303 is -1\n",
      "The prediction for sample 304 is -1\n",
      "The prediction for sample 305 is -1\n",
      "The prediction for sample 306 is -1\n",
      "The prediction for sample 307 is 1\n",
      "The prediction for sample 308 is -1\n",
      "The prediction for sample 309 is -1\n",
      "The prediction for sample 310 is -1\n",
      "The prediction for sample 311 is -1\n",
      "The prediction for sample 312 is -1\n",
      "The prediction for sample 313 is -1\n",
      "The prediction for sample 314 is -1\n",
      "The prediction for sample 315 is 1\n",
      "The prediction for sample 316 is 1\n",
      "The prediction for sample 317 is -1\n",
      "The prediction for sample 318 is -1\n",
      "The prediction for sample 319 is 1\n",
      "The prediction for sample 320 is 1\n",
      "The prediction for sample 321 is 1\n",
      "The prediction for sample 322 is -1\n",
      "The prediction for sample 323 is -1\n",
      "The prediction for sample 324 is 1\n",
      "The prediction for sample 325 is 1\n",
      "The prediction for sample 326 is -1\n",
      "The prediction for sample 327 is 1\n",
      "The prediction for sample 328 is -1\n",
      "The prediction for sample 329 is -1\n",
      "The prediction for sample 330 is 1\n",
      "The prediction for sample 331 is -1\n",
      "The prediction for sample 332 is 1\n",
      "The prediction for sample 333 is -1\n",
      "The prediction for sample 334 is -1\n",
      "The prediction for sample 335 is 1\n",
      "The prediction for sample 336 is 1\n",
      "The prediction for sample 337 is -1\n",
      "The prediction for sample 338 is 1\n",
      "The prediction for sample 339 is 1\n",
      "The prediction for sample 340 is 1\n",
      "The prediction for sample 341 is 1\n",
      "The prediction for sample 342 is 1\n",
      "The prediction for sample 343 is -1\n",
      "The prediction for sample 344 is -1\n",
      "The prediction for sample 345 is -1\n",
      "The prediction for sample 346 is -1\n",
      "The prediction for sample 347 is -1\n",
      "The prediction for sample 348 is -1\n",
      "The prediction for sample 349 is -1\n",
      "The prediction for sample 350 is 1\n",
      "The prediction for sample 351 is -1\n",
      "The prediction for sample 352 is 1\n",
      "The prediction for sample 353 is -1\n",
      "The prediction for sample 354 is -1\n",
      "The prediction for sample 355 is -1\n",
      "The prediction for sample 356 is 1\n",
      "The prediction for sample 357 is -1\n",
      "The prediction for sample 358 is 1\n",
      "The prediction for sample 359 is -1\n",
      "The prediction for sample 360 is -1\n",
      "The prediction for sample 361 is -1\n",
      "The prediction for sample 362 is 1\n",
      "The prediction for sample 363 is -1\n",
      "The prediction for sample 364 is 1\n",
      "The prediction for sample 365 is -1\n",
      "The prediction for sample 366 is 1\n",
      "The prediction for sample 367 is -1\n",
      "The prediction for sample 368 is -1\n",
      "The prediction for sample 369 is 1\n",
      "The prediction for sample 370 is -1\n",
      "The prediction for sample 371 is 1\n",
      "The prediction for sample 372 is -1\n",
      "The prediction for sample 373 is -1\n",
      "The prediction for sample 374 is -1\n",
      "The prediction for sample 375 is 1\n",
      "The prediction for sample 376 is -1\n",
      "The prediction for sample 377 is -1\n",
      "The prediction for sample 378 is -1\n",
      "The prediction for sample 379 is -1\n",
      "The prediction for sample 380 is 1\n",
      "The prediction for sample 381 is -1\n",
      "The prediction for sample 382 is -1\n",
      "The prediction for sample 383 is 1\n",
      "The prediction for sample 384 is 1\n",
      "The prediction for sample 385 is -1\n",
      "The prediction for sample 386 is -1\n",
      "The prediction for sample 387 is -1\n",
      "The prediction for sample 388 is -1\n",
      "The prediction for sample 389 is 1\n",
      "The prediction for sample 390 is -1\n",
      "The prediction for sample 391 is 1\n",
      "The prediction for sample 392 is 1\n",
      "The prediction for sample 393 is 1\n",
      "The prediction for sample 394 is -1\n",
      "The prediction for sample 395 is 1\n",
      "The prediction for sample 396 is -1\n",
      "The prediction for sample 397 is -1\n",
      "The prediction for sample 398 is -1\n",
      "The prediction for sample 399 is 1\n",
      "The prediction for sample 400 is 1\n",
      "The prediction for sample 401 is -1\n",
      "The prediction for sample 402 is 1\n",
      "The prediction for sample 403 is -1\n",
      "The prediction for sample 404 is -1\n",
      "The prediction for sample 405 is 1\n",
      "The prediction for sample 406 is 1\n",
      "The prediction for sample 407 is 1\n",
      "The prediction for sample 408 is 1\n",
      "The prediction for sample 409 is 1\n",
      "The prediction for sample 410 is 1\n",
      "The prediction for sample 411 is 1\n",
      "The prediction for sample 412 is 1\n",
      "The prediction for sample 413 is -1\n",
      "The prediction for sample 414 is 1\n",
      "The prediction for sample 415 is -1\n",
      "The prediction for sample 416 is 1\n",
      "The prediction for sample 417 is -1\n",
      "The prediction for sample 418 is 1\n",
      "The prediction for sample 419 is -1\n",
      "The prediction for sample 420 is -1\n",
      "The prediction for sample 421 is -1\n",
      "The prediction for sample 422 is -1\n",
      "The prediction for sample 423 is 1\n",
      "The prediction for sample 424 is 1\n",
      "The prediction for sample 425 is -1\n",
      "The prediction for sample 426 is -1\n",
      "The prediction for sample 427 is 1\n",
      "The prediction for sample 428 is 1\n",
      "The prediction for sample 429 is 1\n",
      "The prediction for sample 430 is 1\n",
      "The prediction for sample 431 is -1\n",
      "The prediction for sample 432 is -1\n",
      "The prediction for sample 433 is -1\n",
      "The prediction for sample 434 is -1\n",
      "The prediction for sample 435 is -1\n",
      "The prediction for sample 436 is 1\n",
      "The prediction for sample 437 is -1\n",
      "The prediction for sample 438 is 1\n",
      "The prediction for sample 439 is -1\n",
      "The prediction for sample 440 is -1\n",
      "The prediction for sample 441 is -1\n",
      "The prediction for sample 442 is 1\n",
      "The prediction for sample 443 is -1\n",
      "The prediction for sample 444 is -1\n",
      "The prediction for sample 445 is -1\n",
      "The prediction for sample 446 is 1\n",
      "The prediction for sample 447 is -1\n",
      "The prediction for sample 448 is -1\n",
      "The prediction for sample 449 is 1\n",
      "The prediction for sample 450 is -1\n",
      "The prediction for sample 451 is -1\n",
      "The prediction for sample 452 is 1\n",
      "The prediction for sample 453 is 1\n",
      "The prediction for sample 454 is 1\n",
      "The prediction for sample 455 is 1\n",
      "The prediction for sample 456 is -1\n",
      "The prediction for sample 457 is 1\n",
      "The prediction for sample 458 is 1\n",
      "The prediction for sample 459 is -1\n",
      "The prediction for sample 460 is 1\n",
      "The prediction for sample 461 is -1\n",
      "The prediction for sample 462 is -1\n",
      "The prediction for sample 463 is 1\n",
      "The prediction for sample 464 is 1\n",
      "The prediction for sample 465 is -1\n",
      "The prediction for sample 466 is -1\n",
      "The prediction for sample 467 is -1\n",
      "The prediction for sample 468 is -1\n",
      "The prediction for sample 469 is -1\n",
      "The prediction for sample 470 is -1\n",
      "The prediction for sample 471 is -1\n",
      "The prediction for sample 472 is -1\n",
      "The prediction for sample 473 is 1\n",
      "The prediction for sample 474 is -1\n",
      "The prediction for sample 475 is -1\n",
      "The prediction for sample 476 is 1\n",
      "The prediction for sample 477 is -1\n",
      "The prediction for sample 478 is 1\n",
      "The prediction for sample 479 is -1\n",
      "The prediction for sample 480 is 1\n",
      "The prediction for sample 481 is 1\n",
      "The prediction for sample 482 is -1\n",
      "The prediction for sample 483 is 1\n",
      "The prediction for sample 484 is -1\n",
      "The prediction for sample 485 is -1\n",
      "The prediction for sample 486 is -1\n",
      "The prediction for sample 487 is -1\n",
      "The prediction for sample 488 is 1\n",
      "The prediction for sample 489 is -1\n",
      "The prediction for sample 490 is -1\n",
      "The prediction for sample 491 is -1\n"
     ]
    }
   ],
   "source": [
    "guess=p2.predict(tests)\n",
    "\n",
    "for i, item in enumerate(guess):\n",
    "    print(\"The prediction for sample \"+str(i)+\" is \"+str(item))\n",
    "    \n",
    "result=np.column_stack([tests, guess])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21072208, -0.79501808,  0.28437907,  0.86837059,  0.73060236,\n",
       "        -1.        ],\n",
       "       [-0.12111626,  0.60824274, -0.47358205,  0.69620996,  0.21952921,\n",
       "        -1.        ],\n",
       "       [-0.23219499, -0.62105231,  0.05503385,  0.48291495,  0.8759104 ,\n",
       "         1.        ],\n",
       "       ...,\n",
       "       [-0.28960944, -0.15619135,  0.90507601,  0.59775244, -0.09617161,\n",
       "        -1.        ],\n",
       "       [ 0.67907071,  0.00613763,  0.47191729,  0.65510653,  0.4179075 ,\n",
       "        -1.        ],\n",
       "       [ 0.03854587,  0.86104938,  0.23411752, -0.25446469, -0.72048086,\n",
       "        -1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('result.txt','w')\n",
    "for x in result:\n",
    "    print(x, file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
